Index: go/database/mpt/state.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage mpt\n\nimport (\n\t\"bufio\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"maps\"\n\t\"os\"\n\t\"sync\"\n\t\"unsafe\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt/shared\"\n\t\"github.com/Fantom-foundation/Carmen/go/state\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/backend\"\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"golang.org/x/crypto/sha3\"\n)\n\n//go:generate mockgen -source state.go -destination state_mocks.go -package mpt\n\n// Database is a global single access point to Merkle-Patricia-Trie (MPT) data.\n// It contains public methods to retrieve information about accounts\n// and storage slots, furthermore, it allows for  MPT nodes hashing.\n// MPT database maintains a DAG of MPT trees that can be each accessed\n// via a single root node.\n// The database is an appendable storage, where the current state is modified,\n// accessible via the current root node, and eventually sealed and appended\n// to the historical database.\n// Root nodes allow for traversing the respective MPT tree hierarchy\n// to access the history.\n// A Freeze method is provided to seal the current MPT so that further updates\n// will take place on a new version of the MPT.\n// The Current MPT tree may be modified, and the modifications are destructive,\n// until the tree is sealed by Freeze.\ntype Database interface {\n\tcommon.FlushAndCloser\n\tcommon.MemoryFootprintProvider\n\n\t// GetAccountInfo retrieves account information for input root and account address.\n\tGetAccountInfo(rootRef *NodeReference, addr common.Address) (AccountInfo, bool, error)\n\n\t// SetAccountInfo sets the input account into the storage under the input root and the address.\n\tSetAccountInfo(rootRef *NodeReference, addr common.Address, info AccountInfo) (NodeReference, error)\n\n\t// GetValue retrieves storage slot for input root, account address, and storage key.\n\tGetValue(rootRef *NodeReference, addr common.Address, key common.Key) (common.Value, error)\n\n\t// SetValue sets storage slot for input root, account address, and storage key.\n\tSetValue(rootRef *NodeReference, addr common.Address, key common.Key, value common.Value) (NodeReference, error)\n\n\t// ClearStorage removes all storage slots for the input address and the root.\n\tClearStorage(rootRef *NodeReference, addr common.Address) (NodeReference, error)\n\n\t// Freeze seals current trie, preventing further updates to it.\n\tFreeze(ref *NodeReference) error\n\n\t// VisitTrie allows for travertines the whole trie under the input root\n\tVisitTrie(rootRef *NodeReference, visitor NodeVisitor) error\n\n\t// Dump provides a debug print of the whole trie under the input root\n\tDump(rootRef *NodeReference)\n\n\t// Check verifies internal invariants of the Trie instance. If the trie is\n\t// self-consistent, nil is returned and the Trie is ready to be accessed. If\n\t// errors are detected, the Trie is to be considered in an invalid state and\n\t// the behavior of all other operations is undefined.\n\tCheck(rootRef *NodeReference) error\n\n\t// CheckAll verifies internal invariants of a set of Trie instances rooted by\n\t// the given nodes. It is a generalization of the Check() function.\n\tCheckAll(rootRefs []*NodeReference) error\n\n\t// CheckErrors returns an error that might have been\n\t// encountered on this forest in the past.\n\t// If the result is not empty, this\n\t// Forest is to be considered corrupted and should be discarded.\n\tCheckErrors() error\n\n\tupdateHashesFor(ref *NodeReference) (common.Hash, *NodeHashes, error)\n\tsetHashesFor(root *NodeReference, hashes *NodeHashes) error\n}\n\n// LiveState represents a single  Merkle-Patricia-Trie (MPT) view to the Database\n// as it was accessed for a single root.\n// It allows for reading and updating state\n// of accounts, storage slots, and codes.\n// Access to the data is provided via a set of getters,\n// while the update is provides via a single Apply function.\ntype LiveState interface {\n\tcommon.UpdateTarget\n\tcommon.MemoryFootprintProvider\n\tstate.LiveDB\n\n\t// GetHash provides hash root of this MPT.\n\t// The hash is recomputed if it is not available.\n\tGetHash() (hash common.Hash, err error)\n\n\t// GetCodeForHash retrieves bytecode stored\n\t// under the input hash.\n\tGetCodeForHash(hash common.Hash) []byte\n\n\t// GetCodes retrieves all codes and their hashes.\n\tGetCodes() (map[common.Hash][]byte, error)\n\n\t// UpdateHashes recomputes hash root of this trie.\n\tUpdateHashes() (common.Hash, *NodeHashes, error)\n\n\t// Root provides root of this trie.\n\tRoot() NodeReference\n\n\tcloseWithError(externalError error) error\n\tsetHashes(hashes *NodeHashes) error\n}\n\n// MptState implementation of a state utilizes an MPT based data structure. While\n// functionally equivalent to the Ethereum State MPT, hashes are computed using\n// a configurable algorithm.\n//\n// The main role of the MptState is to provide an adapter between a LiveTrie and\n// Carmen's State interface. Also, it retains an index of contract codes.\ntype MptState struct {\n\tdirectory string\n\tlock      common.LockFile\n\ttrie      *LiveTrie\n\tcode      map[common.Hash][]byte\n\tcodeDirty bool\n\tcodeMutex sync.Mutex\n\tcodefile  string\n\thasher    hash.Hash\n}\n\n// The capacity of an MPT's node cache must be at least as large as the maximum\n// number of nodes modified in a block. Evaluations show that most blocks\n// modify less than 2000 nodes. However, one block, presumably the one handling\n// the opera fork at ~4.5M, modifies 434.589 nodes. Thus, the cache size of a\n// MPT processing Fantom's history should be at least ~500.000 nodes.\nconst DefaultMptStateCapacity = 10_000_000\nconst MinMptStateCapacity = 2_000\n\nvar emptyCodeHash = common.GetHash(sha3.NewLegacyKeccak256(), []byte{})\n\nfunc newMptState(directory string, lock common.LockFile, trie *LiveTrie) (*MptState, error) {\n\tcodefile := directory + \"/codes.dat\"\n\tcodes, err := readCodes(codefile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &MptState{\n\t\tdirectory: directory,\n\t\tlock:      lock,\n\t\ttrie:      trie,\n\t\tcode:      codes,\n\t\tcodefile:  codefile,\n\t}, nil\n}\n\nfunc openStateDirectory(directory string) (common.LockFile, error) {\n\tlock, err := LockDirectory(directory)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := tryMarkDirty(directory); err != nil {\n\t\treturn nil, errors.Join(err, lock.Release())\n\t}\n\n\treturn lock, nil\n}\n\nfunc tryMarkDirty(directory string) error {\n\tdirty, err := isDirty(directory)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif dirty {\n\t\treturn fmt.Errorf(\"unable to open %s, content is dirty, likely corrupted\", directory)\n\t}\n\treturn markDirty(directory)\n}\n\n// OpenGoMemoryState loads state information from the given directory and\n// creates a Trie entirely retained in memory.\nfunc OpenGoMemoryState(directory string, config MptConfig, cacheCapacity int) (*MptState, error) {\n\tlock, err := openStateDirectory(directory)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttrie, err := OpenInMemoryLiveTrie(directory, config, cacheCapacity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newMptState(directory, lock, trie)\n}\n\nfunc OpenGoFileState(directory string, config MptConfig, cacheCapacity int) (*MptState, error) {\n\tlock, err := openStateDirectory(directory)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttrie, err := OpenFileLiveTrie(directory, config, cacheCapacity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newMptState(directory, lock, trie)\n}\n\nfunc (s *MptState) CreateAccount(address common.Address) (err error) {\n\t_, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif exists {\n\t\t// For existing accounts, only clear the storage, preserve the rest.\n\t\treturn s.trie.ClearStorage(address)\n\t}\n\t// Create account with hash of empty code.\n\treturn s.trie.SetAccountInfo(address, AccountInfo{\n\t\tCodeHash: emptyCodeHash,\n\t})\n}\n\nfunc (s *MptState) Exists(address common.Address) (bool, error) {\n\t_, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn exists, nil\n}\n\nfunc (s *MptState) DeleteAccount(address common.Address) error {\n\treturn s.trie.SetAccountInfo(address, AccountInfo{})\n}\n\nfunc (s *MptState) GetBalance(address common.Address) (balance common.Balance, err error) {\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif !exists || err != nil {\n\t\treturn common.Balance{}, err\n\t}\n\treturn info.Balance, nil\n}\n\nfunc (s *MptState) SetBalance(address common.Address, balance common.Balance) (err error) {\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif info.Balance == balance {\n\t\treturn nil\n\t}\n\tinfo.Balance = balance\n\tif !exists {\n\t\tinfo.CodeHash = emptyCodeHash\n\t}\n\treturn s.trie.SetAccountInfo(address, info)\n}\n\nfunc (s *MptState) GetNonce(address common.Address) (nonce common.Nonce, err error) {\n\tinfo, _, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn common.Nonce{}, err\n\t}\n\treturn info.Nonce, nil\n}\n\nfunc (s *MptState) SetNonce(address common.Address, nonce common.Nonce) (err error) {\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif info.Nonce == nonce {\n\t\treturn nil\n\t}\n\tinfo.Nonce = nonce\n\tif !exists {\n\t\tinfo.CodeHash = emptyCodeHash\n\t}\n\treturn s.trie.SetAccountInfo(address, info)\n}\n\nfunc (s *MptState) GetStorage(address common.Address, key common.Key) (value common.Value, err error) {\n\treturn s.trie.GetValue(address, key)\n}\n\nfunc (s *MptState) SetStorage(address common.Address, key common.Key, value common.Value) error {\n\treturn s.trie.SetValue(address, key, value)\n}\n\nfunc (s *MptState) GetCode(address common.Address) (value []byte, err error) {\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !exists {\n\t\treturn nil, nil\n\t}\n\ts.codeMutex.Lock()\n\tres := s.code[info.CodeHash]\n\ts.codeMutex.Unlock()\n\treturn res, nil\n}\n\nfunc (s *MptState) GetCodeForHash(hash common.Hash) []byte {\n\ts.codeMutex.Lock()\n\tres := s.code[hash]\n\ts.codeMutex.Unlock()\n\treturn res\n}\n\nfunc (s *MptState) GetCodeSize(address common.Address) (size int, err error) {\n\tcode, err := s.GetCode(address)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn len(code), err\n}\n\nfunc (s *MptState) SetCode(address common.Address, code []byte) (err error) {\n\tvar codeHash common.Hash\n\tif s.hasher == nil {\n\t\ts.hasher = sha3.NewLegacyKeccak256()\n\t}\n\tcodeHash = common.GetHash(s.hasher, code)\n\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !exists && len(code) == 0 {\n\t\treturn nil\n\t}\n\tif info.CodeHash == codeHash {\n\t\treturn nil\n\t}\n\tinfo.CodeHash = codeHash\n\ts.codeMutex.Lock()\n\ts.code[codeHash] = code\n\ts.codeDirty = true\n\ts.codeMutex.Unlock()\n\treturn s.trie.SetAccountInfo(address, info)\n}\n\nfunc (s *MptState) GetCodeHash(address common.Address) (hash common.Hash, err error) {\n\tinfo, exists, err := s.trie.GetAccountInfo(address)\n\tif !exists || err != nil {\n\t\treturn emptyCodeHash, err\n\t}\n\treturn info.CodeHash, nil\n}\n\nfunc (s *MptState) GetRootId() NodeId {\n\treturn s.trie.root.Id()\n}\n\nfunc (s *MptState) GetHash() (hash common.Hash, err error) {\n\thash, hints, err := s.trie.UpdateHashes()\n\tif hints != nil {\n\t\thints.Release()\n\t}\n\treturn hash, err\n}\n\nfunc (s *MptState) Apply(block uint64, update common.Update) (archiveUpdateHints common.Releaser, err error) {\n\tif err := update.ApplyTo(s); err != nil {\n\t\treturn nil, err\n\t}\n\t_, hints, err := s.trie.UpdateHashes()\n\treturn hints, err\n}\n\nfunc (s *MptState) Visit(visitor NodeVisitor) error {\n\treturn s.trie.VisitTrie(visitor)\n}\n\nfunc (s *MptState) GetCodes() (map[common.Hash][]byte, error) {\n\ts.codeMutex.Lock()\n\tres := maps.Clone(s.code)\n\ts.codeMutex.Unlock()\n\treturn res, nil\n}\n\n// Flush codes and state trie\nfunc (s *MptState) Flush() error {\n\t// flush codes\n\tvar err error\n\ts.codeMutex.Lock()\n\tif s.codeDirty {\n\t\terr = writeCodes(s.code, s.codefile)\n\t\tif err == nil {\n\t\t\ts.codeDirty = false\n\t\t}\n\t}\n\ts.codeMutex.Unlock()\n\treturn errors.Join(\n\t\ts.trie.forest.CheckErrors(),\n\t\terr,\n\t\ts.trie.Flush(),\n\t)\n}\n\nfunc (s *MptState) Close() error {\n\treturn s.closeWithError(nil)\n}\n\nfunc (s *MptState) closeWithError(externalError error) error {\n\t// Only if the state can be successfully closed, the directory is to\n\t// be marked as clean. Otherwise, the dirty flag needs to be retained.\n\terr := errors.Join(\n\t\texternalError,\n\t\ts.Flush(),\n\t\ts.trie.Close(),\n\t)\n\tif err == nil {\n\t\terr = markClean(s.directory)\n\t}\n\treturn errors.Join(\n\t\terr,\n\t\ts.lock.Release(),\n\t)\n}\n\nfunc (s *MptState) GetSnapshotableComponents() []backend.Snapshotable {\n\t//panic(\"not implemented\")\n\treturn nil\n}\n\nfunc (s *MptState) RunPostRestoreTasks() error {\n\t//panic(\"not implemented\")\n\treturn nil\n}\n\n// GetMemoryFootprint provides sizes of individual components of the state in the memory\nfunc (s *MptState) GetMemoryFootprint() *common.MemoryFootprint {\n\tmf := common.NewMemoryFootprint(unsafe.Sizeof(*s))\n\tmf.AddChild(\"trie\", s.trie.GetMemoryFootprint())\n\tvar sizeCodes uint\n\ts.codeMutex.Lock()\n\tfor k, v := range s.code {\n\t\tsizeCodes += uint(len(k) + len(v))\n\t}\n\ts.codeMutex.Unlock()\n\tmf.AddChild(\"codes\", common.NewMemoryFootprint(uintptr(sizeCodes)))\n\treturn mf\n}\n\nfunc (s *MptState) UpdateHashes() (common.Hash, *NodeHashes, error) {\n\treturn s.trie.UpdateHashes()\n}\n\nfunc (s *MptState) Root() NodeReference {\n\treturn s.trie.root\n}\n\nfunc (s *MptState) setHashes(hashes *NodeHashes) error {\n\treturn s.trie.setHashes(hashes)\n}\n\n// readCodes parses the content of the given file if it exists or returns\n// a an empty code collection if there is no such file.\nfunc readCodes(filename string) (map[common.Hash][]byte, error) {\n\t// If there is no file, initialize and return an empty code collection.\n\tif _, err := os.Stat(filename); err != nil {\n\t\treturn map[common.Hash][]byte{}, nil\n\t}\n\n\tfile, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer file.Close()\n\treader := bufio.NewReader(file)\n\treturn parseCodes(reader)\n}\n\nfunc parseCodes(reader io.Reader) (map[common.Hash][]byte, error) {\n\t// If the file exists, parse it and return its content.\n\tres := map[common.Hash][]byte{}\n\t// The format is simple: [<key>, <length>, <code>]*\n\tvar hash common.Hash\n\tvar length [4]byte\n\tfor {\n\t\tif _, err := io.ReadFull(reader, hash[:]); err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn res, nil\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tif _, err := io.ReadFull(reader, length[:]); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsize := binary.BigEndian.Uint32(length[:])\n\t\tcode := make([]byte, size)\n\t\tif _, err := io.ReadFull(reader, code[:]); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tres[hash] = code\n\t}\n}\n\n// writeCodes write the given map of codes to the given file.\nfunc writeCodes(codes map[common.Hash][]byte, filename string) (err error) {\n\tfile, err := os.Create(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\twriter := bufio.NewWriter(file)\n\treturn errors.Join(\n\t\twriteCodesTo(codes, writer),\n\t\twriter.Flush(),\n\t\tfile.Close())\n}\n\nfunc writeCodesTo(codes map[common.Hash][]byte, writer io.Writer) (err error) {\n\t// The format is simple: [<key>, <length>, <code>]*\n\tfor key, code := range codes {\n\t\tif _, err := writer.Write(key[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvar length [4]byte\n\t\tbinary.BigEndian.PutUint32(length[:], uint32(len(code)))\n\t\tif _, err := writer.Write(length[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := writer.Write(code); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// EstimatePerNodeMemoryUsage returns an estimated upper bound for the\n// amount of memory used per MPT node. This values is provided to facilitate\n// a conversion between memory limits expressed in bytes and MPT cache\n// sizes defined by the number of stored nodes.\nfunc EstimatePerNodeMemoryUsage() int {\n\n\t// The largest node is the BranchNode with ~944 bytes, which is\n\t// likely allocated into 1 KB memory slots. Thus, a memory usage\n\t// of 1 KB is used for the notes\n\tmaxNodeSize := 1 << 10\n\n\t// Additionally, every node in the node cache needs a owner slot\n\t// and a NodeID/ownerPosition entry pair in the index of the cache.\n\tnodeCacheSlotSize := unsafe.Sizeof(nodeOwner{}) +\n\t\tunsafe.Sizeof(NodeId(0)) +\n\t\tunsafe.Sizeof(ownerPosition(0)) +\n\t\tunsafe.Sizeof(shared.Shared[Node]{})\n\n\treturn maxNodeSize + int(nodeCacheSlotSize)\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/state.go b/go/database/mpt/state.go
--- a/go/database/mpt/state.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/state.go	(date 1717067261810)
@@ -12,6 +12,7 @@
 
 import (
 	"bufio"
+	"context"
 	"encoding/binary"
 	"errors"
 	"fmt"
@@ -141,6 +142,7 @@
 	codeMutex sync.Mutex
 	codefile  string
 	hasher    hash.Hash
+	ctx       context.Context
 }
 
 // The capacity of an MPT's node cache must be at least as large as the maximum
@@ -153,7 +155,7 @@
 
 var emptyCodeHash = common.GetHash(sha3.NewLegacyKeccak256(), []byte{})
 
-func newMptState(directory string, lock common.LockFile, trie *LiveTrie) (*MptState, error) {
+func newMptState(directory string, lock common.LockFile, trie *LiveTrie, ctx context.Context) (*MptState, error) {
 	codefile := directory + "/codes.dat"
 	codes, err := readCodes(codefile)
 	if err != nil {
@@ -165,6 +167,7 @@
 		trie:      trie,
 		code:      codes,
 		codefile:  codefile,
+		ctx:       ctx,
 	}, nil
 }
 
@@ -202,7 +205,7 @@
 	if err != nil {
 		return nil, err
 	}
-	return newMptState(directory, lock, trie)
+	return newMptState(directory, lock, trie, context.Background())
 }
 
 func OpenGoFileState(directory string, config MptConfig, cacheCapacity int) (*MptState, error) {
@@ -214,7 +217,19 @@
 	if err != nil {
 		return nil, err
 	}
-	return newMptState(directory, lock, trie)
+	return newMptState(directory, lock, trie, context.Background())
+}
+
+func OpenGoFileStateWithContext(directory string, config MptConfig, cacheCapacity int, ctx context.Context) (*MptState, error) {
+	lock, err := openStateDirectory(directory)
+	if err != nil {
+		return nil, err
+	}
+	trie, err := OpenFileLiveTrie(directory, config, cacheCapacity)
+	if err != nil {
+		return nil, err
+	}
+	return newMptState(directory, lock, trie, ctx)
 }
 
 func (s *MptState) CreateAccount(address common.Address) (err error) {
Index: go/database/mpt/archive_trie.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage mpt\n\nimport (\n\t\"bufio\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"sync\"\n\t\"unsafe\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n)\n\n// ArchiveTrie retains a per-block history of the state trie. Each state is\n// a trie in a Forest of which the root node is retained. Updates can only\n// be applied through the `Add` method, according to the `archive.Archive“\n// interface, which this type is implementing.\n//\n// Its main task is to keep track of state roots and to freeze the head\n// state after each block.\ntype ArchiveTrie struct {\n\thead         LiveState // the current head-state\n\tforest       Database  // global forest with all versions of LiveState\n\tnodeSource   NodeSource\n\troots        []Root     // the roots of individual blocks indexed by block height\n\trootsMutex   sync.Mutex // protecting access to the roots list\n\trootFile     string     // the file storing the list of roots\n\taddMutex     sync.Mutex // a mutex to make sure that at any time only one thread is adding new blocks\n\terrorMutex   sync.RWMutex\n\tarchiveError error // a non-nil error will be stored here should it occur during any archive operation\n}\n\nfunc OpenArchiveTrie(directory string, config MptConfig, cacheCapacity int) (*ArchiveTrie, error) {\n\tlock, err := openStateDirectory(directory)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\trootfile := directory + \"/roots.dat\"\n\troots, err := loadRoots(rootfile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tforestConfig := ForestConfig{Mode: Immutable, CacheCapacity: cacheCapacity}\n\tforest, err := OpenFileForest(directory, config, forestConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thead, err := makeTrie(directory, forest)\n\tif err != nil {\n\t\tforest.Close()\n\t\treturn nil, err\n\t}\n\tstate, err := newMptState(directory, lock, head)\n\tif err != nil {\n\t\thead.Close()\n\t\treturn nil, err\n\t}\n\treturn &ArchiveTrie{\n\t\thead:       state,\n\t\tforest:     forest,\n\t\tnodeSource: forest,\n\t\troots:      roots,\n\t\trootFile:   rootfile,\n\t}, nil\n}\n\nfunc VerifyArchive(directory string, config MptConfig, observer VerificationObserver) error {\n\troots, err := loadRoots(directory + \"/roots.dat\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(roots) == 0 {\n\t\treturn nil\n\t}\n\treturn VerifyFileForest(directory, config, roots, observer)\n}\n\nfunc (a *ArchiveTrie) Add(block uint64, update common.Update, hint any) error {\n\tif err := a.CheckErrors(); err != nil {\n\t\treturn err\n\t}\n\n\tprecomputedHashes, _ := hint.(*NodeHashes)\n\n\ta.addMutex.Lock()\n\tdefer a.addMutex.Unlock()\n\n\ta.rootsMutex.Lock()\n\tif uint64(len(a.roots)) > block {\n\t\ta.rootsMutex.Unlock()\n\t\treturn fmt.Errorf(\"block %d already present\", block)\n\t}\n\n\t// Mark skipped blocks as having no changes.\n\tif uint64(len(a.roots)) < block {\n\t\tlastHash, err := a.head.GetHash()\n\t\tif err != nil {\n\t\t\ta.rootsMutex.Unlock()\n\t\t\treturn a.addError(err)\n\t\t}\n\t\tfor uint64(len(a.roots)) < block {\n\t\t\ta.roots = append(a.roots, Root{a.head.Root(), lastHash})\n\t\t}\n\t}\n\ta.rootsMutex.Unlock()\n\n\t// Apply all the changes of the update.\n\tif err := update.ApplyTo(a.head); err != nil {\n\t\treturn a.addError(err)\n\t}\n\n\t// Freeze new state.\n\troot := a.head.Root()\n\tif err := a.forest.Freeze(&root); err != nil {\n\t\treturn a.addError(err)\n\t}\n\n\t// Refresh hashes.\n\tvar err error\n\tvar hash common.Hash\n\tif precomputedHashes == nil {\n\t\tvar hashes *NodeHashes\n\t\thash, hashes, err = a.head.UpdateHashes()\n\t\tif hashes != nil {\n\t\t\thashes.Release()\n\t\t}\n\t} else {\n\t\terr = a.head.setHashes(precomputedHashes)\n\t\tif err == nil {\n\t\t\thash, err = a.head.GetHash()\n\t\t}\n\t}\n\tif err != nil {\n\t\treturn a.addError(err)\n\t}\n\n\t// Save new root node.\n\ta.rootsMutex.Lock()\n\ta.roots = append(a.roots, Root{a.head.Root(), hash})\n\ta.rootsMutex.Unlock()\n\treturn nil\n}\n\nfunc (a *ArchiveTrie) GetBlockHeight() (block uint64, empty bool, err error) {\n\ta.rootsMutex.Lock()\n\tlength := uint64(len(a.roots))\n\ta.rootsMutex.Unlock()\n\tif length == 0 {\n\t\treturn 0, true, nil\n\t}\n\treturn length - 1, false, nil\n}\n\nfunc (a *ArchiveTrie) Exists(block uint64, account common.Address) (exists bool, err error) {\n\tview, err := a.getView(block)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\t_, exists, err = view.GetAccountInfo(account)\n\tif err != nil {\n\t\treturn false, a.addError(err)\n\t}\n\treturn exists, err\n}\n\nfunc (a *ArchiveTrie) GetBalance(block uint64, account common.Address) (balance common.Balance, err error) {\n\tview, err := a.getView(block)\n\tif err != nil {\n\t\treturn common.Balance{}, err\n\t}\n\tinfo, _, err := view.GetAccountInfo(account)\n\tif err != nil {\n\t\treturn common.Balance{}, a.addError(err)\n\t}\n\treturn info.Balance, nil\n}\n\nfunc (a *ArchiveTrie) GetCode(block uint64, account common.Address) (code []byte, err error) {\n\tview, err := a.getView(block)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo, _, err := view.GetAccountInfo(account)\n\tif err != nil {\n\t\treturn nil, a.addError(err)\n\t}\n\treturn a.head.GetCodeForHash(info.CodeHash), nil\n}\n\nfunc (a *ArchiveTrie) GetCodes() (map[common.Hash][]byte, error) {\n\treturn a.head.GetCodes()\n}\n\nfunc (a *ArchiveTrie) GetNonce(block uint64, account common.Address) (nonce common.Nonce, err error) {\n\tview, err := a.getView(block)\n\tif err != nil {\n\t\treturn common.Nonce{}, err\n\t}\n\tinfo, _, err := view.GetAccountInfo(account)\n\tif err != nil {\n\t\treturn common.Nonce{}, a.addError(err)\n\t}\n\treturn info.Nonce, nil\n}\n\nfunc (a *ArchiveTrie) GetStorage(block uint64, account common.Address, slot common.Key) (value common.Value, err error) {\n\tview, err := a.getView(block)\n\tif err != nil {\n\t\treturn common.Value{}, a.addError(err)\n\t}\n\treturn view.GetValue(account, slot)\n}\n\nfunc (a *ArchiveTrie) GetAccountHash(block uint64, account common.Address) (common.Hash, error) {\n\treturn common.Hash{}, fmt.Errorf(\"not implemented\")\n}\n\nfunc (a *ArchiveTrie) GetHash(block uint64) (hash common.Hash, err error) {\n\ta.rootsMutex.Lock()\n\tlength := uint64(len(a.roots))\n\tif block >= length {\n\t\ta.rootsMutex.Unlock()\n\t\treturn common.Hash{}, fmt.Errorf(\"invalid block: %d >= %d\", block, length)\n\t}\n\tres := a.roots[block].Hash\n\ta.rootsMutex.Unlock()\n\treturn res, nil\n}\n\n// GetDiff computes the difference between the given source and target blocks.\nfunc (a *ArchiveTrie) GetDiff(srcBlock, trgBlock uint64) (Diff, error) {\n\ta.rootsMutex.Lock()\n\tif srcBlock >= uint64(len(a.roots)) {\n\t\ta.rootsMutex.Unlock()\n\t\treturn Diff{}, fmt.Errorf(\"source block %d not present in archive, highest block is %d\", srcBlock, len(a.roots)-1)\n\t}\n\tif trgBlock >= uint64(len(a.roots)) {\n\t\ta.rootsMutex.Unlock()\n\t\treturn Diff{}, fmt.Errorf(\"target block %d not present in archive, highest block is %d\", trgBlock, len(a.roots)-1)\n\t}\n\tbefore := a.roots[srcBlock].NodeRef\n\tafter := a.roots[trgBlock].NodeRef\n\ta.rootsMutex.Unlock()\n\treturn GetDiff(a.nodeSource, &before, &after)\n}\n\n// GetDiffForBlock computes the diff introduced by the given block compared to its\n// predecessor. Note that this enables access to the changes introduced by block 0.\nfunc (a *ArchiveTrie) GetDiffForBlock(block uint64) (Diff, error) {\n\tif block == 0 {\n\t\ta.rootsMutex.Lock()\n\t\tif len(a.roots) == 0 {\n\t\t\ta.rootsMutex.Unlock()\n\t\t\treturn Diff{}, fmt.Errorf(\"archive is empty, no diff present for block 0\")\n\t\t}\n\t\tafter := a.roots[0].NodeRef\n\t\ta.rootsMutex.Unlock()\n\t\treturn GetDiff(a.nodeSource, &emptyNodeReference, &after)\n\t}\n\treturn a.GetDiff(block-1, block)\n}\n\nfunc (a *ArchiveTrie) GetMemoryFootprint() *common.MemoryFootprint {\n\tmf := common.NewMemoryFootprint(unsafe.Sizeof(*a))\n\tmf.AddChild(\"head\", a.head.GetMemoryFootprint())\n\ta.rootsMutex.Lock()\n\tmf.AddChild(\"roots\", common.NewMemoryFootprint(uintptr(len(a.roots))*unsafe.Sizeof(NodeId(0))))\n\ta.rootsMutex.Unlock()\n\treturn mf\n}\n\nfunc (a *ArchiveTrie) Check() error {\n\troots := make([]*NodeReference, len(a.roots))\n\tfor i := 0; i < len(a.roots); i++ {\n\t\troots[i] = &a.roots[i].NodeRef\n\t}\n\treturn errors.Join(\n\t\ta.CheckErrors(),\n\t\ta.forest.CheckAll(roots))\n}\n\nfunc (a *ArchiveTrie) Dump() {\n\ta.rootsMutex.Lock()\n\tdefer a.rootsMutex.Unlock()\n\tfor i, root := range a.roots {\n\t\tfmt.Printf(\"\\nBlock %d: %x\\n\", i, root.Hash)\n\t\tview := getTrieView(root.NodeRef, a.forest)\n\t\tview.Dump()\n\t\tfmt.Printf(\"\\n\")\n\t}\n}\n\nfunc (a *ArchiveTrie) Flush() error {\n\ta.rootsMutex.Lock()\n\tdefer a.rootsMutex.Unlock()\n\treturn errors.Join(\n\t\ta.CheckErrors(),\n\t\ta.head.Flush(),\n\t\tStoreRoots(a.rootFile, a.roots),\n\t)\n}\n\nfunc (a *ArchiveTrie) Close() error {\n\treturn errors.Join(\n\t\ta.CheckErrors(),\n\t\ta.head.closeWithError(a.Flush()))\n}\n\nfunc (a *ArchiveTrie) getView(block uint64) (*LiveTrie, error) {\n\tif err := a.CheckErrors(); err != nil {\n\t\treturn nil, err\n\t}\n\n\ta.rootsMutex.Lock()\n\tlength := uint64(len(a.roots))\n\tif block >= length {\n\t\ta.rootsMutex.Unlock()\n\t\treturn nil, fmt.Errorf(\"invalid block: %d >= %d\", block, length)\n\t}\n\trootRef := a.roots[block].NodeRef\n\ta.rootsMutex.Unlock()\n\treturn getTrieView(rootRef, a.forest), nil\n}\n\n// CheckErrors returns a non-nil error should any error\n// happen during any operation in this archive.\n// In particular, updating this archive or getting\n// values out of it may fail, and in this case,\n// the error is stored and returned in this method.\n// Further calls to this archive produce the same\n// error as this method returns.\nfunc (a *ArchiveTrie) CheckErrors() error {\n\ta.errorMutex.RLock()\n\tdefer a.errorMutex.RUnlock()\n\treturn a.archiveError\n}\n\nfunc (a *ArchiveTrie) addError(err error) error {\n\ta.errorMutex.Lock()\n\tdefer a.errorMutex.Unlock()\n\ta.archiveError = errors.Join(a.archiveError, err)\n\treturn a.archiveError\n}\n\n// ---- Reading and Writing Root Node ID Lists ----\n\nfunc loadRoots(filename string) ([]Root, error) {\n\t// If there is no file, initialize and return an empty list.\n\tif _, err := os.Stat(filename); err != nil {\n\t\treturn nil, nil\n\t}\n\n\tf, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\treader := bufio.NewReader(f)\n\treturn loadRootsFrom(reader)\n}\n\nfunc loadRootsFrom(reader io.Reader) ([]Root, error) {\n\tres := []Root{}\n\tencoder := NodeIdEncoder{}\n\tbuffer := make([]byte, encoder.GetEncodedSize())\n\tvar hash common.Hash\n\tfor {\n\t\tif _, err := io.ReadFull(reader, buffer); err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn res, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"invalid root file format: %v\", err)\n\t\t}\n\n\t\tif _, err := io.ReadFull(reader, hash[:]); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid root file format: %v\", err)\n\t\t}\n\n\t\tvar id NodeId\n\t\tencoder.Load(buffer, &id)\n\t\tres = append(res, Root{NewNodeReference(id), hash})\n\t}\n}\n\nfunc StoreRoots(filename string, roots []Root) error {\n\tf, err := os.Create(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\twriter := bufio.NewWriter(f)\n\treturn errors.Join(\n\t\tstoreRootsTo(writer, roots),\n\t\twriter.Flush(),\n\t\tf.Close())\n}\n\nfunc storeRootsTo(writer io.Writer, roots []Root) error {\n\t// Simple file format: [<node-id><state-hash>]*\n\tencoder := NodeIdEncoder{}\n\tbuffer := make([]byte, encoder.GetEncodedSize())\n\tfor _, root := range roots {\n\t\tencoder.Store(buffer, &root.NodeRef.id)\n\t\tif _, err := writer.Write(buffer[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := writer.Write(root.Hash[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/archive_trie.go b/go/database/mpt/archive_trie.go
--- a/go/database/mpt/archive_trie.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/archive_trie.go	(date 1717067247367)
@@ -61,7 +61,7 @@
 		forest.Close()
 		return nil, err
 	}
-	state, err := newMptState(directory, lock, head)
+	state, err := newMptState(directory, lock, head, nil)
 	if err != nil {
 		head.Close()
 		return nil, err
Index: go/database/mpt/tool/export.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage main\n\nimport (\n\t\"bufio\"\n\t\"compress/gzip\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt\"\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt/io\"\n\t\"github.com/urfave/cli/v2\"\n)\n\nvar ExportCmd = cli.Command{\n\tAction:    doExport,\n\tName:      \"export\",\n\tUsage:     \"exports a LiveDB or Archive instance into a file\",\n\tArgsUsage: \"<db director> <target-file>\",\n\tFlags: []cli.Flag{\n\t\t&cpuProfileFlag,\n\t},\n}\n\nfunc doExport(context *cli.Context) error {\n\tif context.Args().Len() != 2 {\n\t\treturn fmt.Errorf(\"missing state directory and/or target file parameter\")\n\t}\n\tdir := context.Args().Get(0)\n\ttrg := context.Args().Get(1)\n\n\t// Start profiling ...\n\tcpuProfileFileName := context.String(cpuProfileFlag.Name)\n\tif strings.TrimSpace(cpuProfileFileName) != \"\" {\n\t\tif err := startCpuProfiler(cpuProfileFileName); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer stopCpuProfiler()\n\t}\n\n\t// check the type of target database\n\tmptInfo, err := io.CheckMptDirectoryAndGetInfo(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\texport := io.Export\n\tif mptInfo.Mode == mpt.Immutable {\n\t\texport = io.ExportArchive\n\t}\n\n\tstart := time.Now()\n\tlogFromStart(start, \"export started\")\n\tfile, err := os.Create(trg)\n\tif err != nil {\n\t\treturn err\n\t}\n\tbufferedWriter := bufio.NewWriter(file)\n\tout := gzip.NewWriter(bufferedWriter)\n\tdefer func() {\n\t\tlogFromStart(start, \"export done\")\n\t}()\n\treturn errors.Join(\n\t\texport(dir, out),\n\t\tout.Close(),\n\t\tbufferedWriter.Flush(),\n\t\tfile.Close(),\n\t)\n}\n\nfunc logFromStart(start time.Time, msg string) {\n\tnow := time.Now()\n\tt := uint64(now.Sub(start).Seconds())\n\tlog.Printf(\"[t=%4d:%02d] - %s.\\n\", t/60, t%60, msg)\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/tool/export.go b/go/database/mpt/tool/export.go
--- a/go/database/mpt/tool/export.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/tool/export.go	(date 1717067196530)
@@ -13,10 +13,12 @@
 import (
 	"bufio"
 	"compress/gzip"
+	"context"
 	"errors"
 	"fmt"
 	"log"
 	"os"
+	"os/signal"
 	"strings"
 	"time"
 
@@ -35,15 +37,15 @@
 	},
 }
 
-func doExport(context *cli.Context) error {
-	if context.Args().Len() != 2 {
+func doExport(cliCtx *cli.Context) error {
+	if cliCtx.Args().Len() != 2 {
 		return fmt.Errorf("missing state directory and/or target file parameter")
 	}
-	dir := context.Args().Get(0)
-	trg := context.Args().Get(1)
+	dir := cliCtx.Args().Get(0)
+	trg := cliCtx.Args().Get(1)
 
 	// Start profiling ...
-	cpuProfileFileName := context.String(cpuProfileFlag.Name)
+	cpuProfileFileName := cliCtx.String(cpuProfileFlag.Name)
 	if strings.TrimSpace(cpuProfileFileName) != "" {
 		if err := startCpuProfiler(cpuProfileFileName); err != nil {
 			return err
@@ -70,11 +72,29 @@
 	}
 	bufferedWriter := bufio.NewWriter(file)
 	out := gzip.NewWriter(bufferedWriter)
+
+	// trap Ctrl+C and call cancel on the context
+	ctx, cancel := context.WithCancel(cliCtx.Context)
+	c := make(chan os.Signal, 1)
+	signal.Notify(c, os.Interrupt)
 	defer func() {
+		signal.Stop(c)
+		cancel()
+
+	}()
+	go func() {
+		select {
+		case <-c:
+			logFromStart(start, "export canceled, gracefully closing db")
+			cancel()
+			os.Exit(2)
+		case <-ctx.Done():
+		}
 		logFromStart(start, "export done")
 	}()
+
 	return errors.Join(
-		export(dir, out),
+		export(dir, out, ctx),
 		out.Close(),
 		bufferedWriter.Flush(),
 		file.Close(),
Index: go/database/mpt/io/archive.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage io\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"sort\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/state\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/backend/archive\"\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt\"\n\t\"golang.org/x/exp/maps\"\n)\n\n// This file provides a pair of import and export functions capable of\n// serializing the content of an Archive into a single, payload-only data\n// blob with build-in consistency check which can be utilized for safely\n// transferring state information between systems.\n//\n// Format:\n//\n//  file   ::= <magic-number> <version> [<code>]* [<update>]*\n//  code   ::= 'C' <2-byte big-endian code length> <code>\n//  update ::= 'U' <4-byte big-endian block> [<hash>]+ [<change>]+\n//  hash   ::= 'H' <1-byte hash type identifier> <state-hash>\n//  change ::= 'A' <address>           // starts a new account scope\n//           | 'R'                     // reset the current account\n//           | 'B' <balance>           // update the current account's balance\n//           | 'N' <nonce>             // update the current account's nonce\n//           | 'c' <code-hash>         // update the current account's code\n//           | 'V' <key> <value>       // update the value of a storage slot\n//           | 'D' <key>               // delete a storage slot\n//\n// All properties belong to the account preceding it. The produced data stream\n// may be further compressed (e.g. using Gzip) to reduce its size.\n\nvar archiveMagicNumber []byte = []byte(\"Fantom-Archive-State\")\n\nconst archiveFormatVersion = byte(1)\n\nfunc ExportArchive(directory string, out io.Writer) error {\n\n\tinfo, err := CheckMptDirectoryAndGetInfo(directory)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error in input directory: %v\", err)\n\t}\n\n\tif info.Config.Name != mpt.S5ArchiveConfig.Name {\n\t\treturn fmt.Errorf(\"can only support export of S5 Archive instances, found %v in directory\", info.Config.Name)\n\t}\n\n\tarchive, err := mpt.OpenArchiveTrie(directory, info.Config, mpt.DefaultMptStateCapacity)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Start with the magic number.\n\tif _, err := out.Write(archiveMagicNumber); err != nil {\n\t\treturn err\n\t}\n\n\t// Add a version number.\n\tif _, err := out.Write([]byte{archiveFormatVersion}); err != nil {\n\t\treturn err\n\t}\n\n\t// Write out codes.\n\tcodes, err := archive.GetCodes()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to retrieve codes: %v\", err)\n\t}\n\tif err := writeCodes(codes, out); err != nil {\n\t\treturn err\n\t}\n\n\t// Write out updates.\n\tmaxBlock, empty, err := archive.GetBlockHeight()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get max block height: %w\", err)\n\t}\n\tif empty {\n\t\treturn archive.Close()\n\t}\n\n\t// Encode diff of each individual block.\n\tfor block := uint64(0); block <= maxBlock; block++ {\n\t\tdiff, err := archive.GetDiffForBlock(block)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to get diff for block %d: %w\", block, err)\n\t\t}\n\t\tif len(diff) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Encode block number.\n\t\tb := []byte{byte('U'), 0, 0, 0, 0}\n\t\tbinary.BigEndian.PutUint32(b[1:], uint32(block))\n\t\tif _, err := out.Write(b); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Encode the block hash.\n\t\thash, err := archive.GetHash(block)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := out.Write([]byte{byte('H'), byte(EthereumHash)}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := out.Write(hash[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Encode changes of this block.\n\t\taddresses := maps.Keys(diff)\n\t\tsort.Slice(addresses, func(i, j int) bool { return bytes.Compare(addresses[i][:], addresses[j][:]) < 0 })\n\t\tfor _, address := range addresses {\n\t\t\tif _, err := out.Write([]byte{'A'}); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif _, err := out.Write(address[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\taccountDiff := diff[address]\n\t\t\tif accountDiff.Reset {\n\t\t\t\tif _, err := out.Write([]byte{'R'}); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif accountDiff.Balance != nil {\n\t\t\t\tif _, err := out.Write([]byte{'B'}); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif _, err := out.Write((*accountDiff.Balance)[:]); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif accountDiff.Nonce != nil {\n\t\t\t\tif _, err := out.Write([]byte{'N'}); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif _, err := out.Write((*accountDiff.Nonce)[:]); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif accountDiff.Code != nil {\n\t\t\t\tif _, err := out.Write([]byte{'c'}); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif _, err := out.Write((*accountDiff.Code)[:]); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tkeys := maps.Keys(accountDiff.Storage)\n\t\t\tsort.Slice(keys, func(i, j int) bool { return bytes.Compare(keys[i][:], keys[j][:]) < 0 })\n\t\t\tfor _, key := range keys {\n\t\t\t\tvalue := accountDiff.Storage[key]\n\t\t\t\tif (value == common.Value{}) {\n\t\t\t\t\tif _, err := out.Write([]byte{'D'}); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif _, err := out.Write(key[:]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif _, err := out.Write([]byte{'V'}); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif _, err := out.Write(key[:]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif _, err := out.Write(value[:]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn archive.Close()\n}\n\nfunc ImportArchive(directory string, in io.Reader) error {\n\t// check that the destination directory is an empty directory\n\tif err := checkEmptyDirectory(directory); err != nil {\n\t\treturn err\n\t}\n\tliveDbDir := path.Join(directory, \"tmp-live-db\")\n\treturn errors.Join(\n\t\timportArchive(liveDbDir, directory, in),\n\t\tos.RemoveAll(liveDbDir), // live db is deleted at the end\n\t)\n}\n\nfunc ImportLiveAndArchive(directory string, in io.Reader) error {\n\t// check that the destination directory is an empty directory\n\tif err := checkEmptyDirectory(directory); err != nil {\n\t\treturn err\n\t}\n\tliveDbDir := path.Join(directory, \"live\")\n\tarchiveDbDir := path.Join(directory, \"archive\")\n\treturn importArchive(liveDbDir, archiveDbDir, in)\n}\n\nfunc importArchive(liveDbDir, archiveDbDir string, in io.Reader) (err error) {\n\t// Start by checking the magic number.\n\tbuffer := make([]byte, len(archiveMagicNumber))\n\tif _, err := io.ReadFull(in, buffer); err != nil {\n\t\treturn err\n\t} else if !bytes.Equal(buffer, archiveMagicNumber) {\n\t\treturn fmt.Errorf(\"invalid format, wrong magic number\")\n\t}\n\n\t// Check the version number.\n\tif _, err := io.ReadFull(in, buffer[0:1]); err != nil {\n\t\treturn err\n\t} else if buffer[0] != archiveFormatVersion {\n\t\treturn fmt.Errorf(\"invalid format, unsupported version\")\n\t}\n\n\t// Create a live-DB updated in parallel for faster hash computation.\n\tlive, err := mpt.OpenGoFileState(liveDbDir, mpt.S5LiveConfig, mpt.DefaultMptStateCapacity)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create auxiliary live DB: %w\", err)\n\t}\n\tdefer func() {\n\t\terr = errors.Join(\n\t\t\terr,\n\t\t\tlive.Close(),\n\t\t)\n\t}()\n\n\t// Create an empty archive.\n\tarchive, err := mpt.OpenArchiveTrie(archiveDbDir, mpt.S5ArchiveConfig, mpt.DefaultMptStateCapacity)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create empty state: %w\", err)\n\t}\n\tdefer func() {\n\t\terr = errors.Join(err, archive.Close())\n\t}()\n\n\t// Restore the archive from the input file.\n\tcontext := newImportContext()\n\tfor {\n\t\t// Read prefix determining the next input marker.\n\t\tif _, err := io.ReadFull(in, buffer[0:1]); err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn context.finishCurrentBlock(archive, live)\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tswitch buffer[0] {\n\t\tcase 'A':\n\t\t\taddress := common.Address{}\n\t\t\tif _, err := io.ReadFull(in, address[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.setAccount(address)\n\t\tcase 'C':\n\t\t\tcode, err := readCode(in)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.addCode(code)\n\t\tcase 'U':\n\t\t\tif err := context.finishCurrentBlock(archive, live); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, buffer[0:4]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.setBlock(uint64(binary.BigEndian.Uint32(buffer)))\n\n\t\tcase 'H':\n\t\t\tif _, err := io.ReadFull(in, buffer[0:1]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\thashType := HashType(buffer[0])\n\t\t\thash := common.Hash{}\n\t\t\tif _, err := io.ReadFull(in, hash[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif hashType == EthereumHash {\n\t\t\t\tcontext.setBlockHash(hash)\n\t\t\t}\n\n\t\tcase 'R':\n\t\t\tcontext.deleteAccount()\n\n\t\tcase 'B':\n\t\t\tbalance := common.Balance{}\n\t\t\tif _, err := io.ReadFull(in, balance[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.setBalance(balance)\n\n\t\tcase 'N':\n\t\t\tnonce := common.Nonce{}\n\t\t\tif _, err := io.ReadFull(in, nonce[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.setNonce(nonce)\n\n\t\tcase 'c':\n\t\t\thash := common.Hash{}\n\t\t\tif _, err := io.ReadFull(in, hash[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := context.setCode(hash); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\tcase 'V':\n\t\t\tkey := common.Key{}\n\t\t\tvalue := common.Value{}\n\t\t\tif _, err := io.ReadFull(in, key[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, value[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.setSlot(key, value)\n\n\t\tcase 'D':\n\t\t\tkey := common.Key{}\n\t\t\tif _, err := io.ReadFull(in, key[:]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontext.deleteSlot(key)\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"format error encountered, unexpected token type: %c\", buffer[0])\n\t\t}\n\t}\n}\n\ntype importContext struct {\n\tcodes                 map[common.Hash][]byte\n\tcurrentAccount        common.Address\n\tcurrentBlock          uint64\n\tcurrentBlockHash      common.Hash\n\tcurrentBlockHashFound bool\n\tcurrentUpdate         common.Update\n}\n\nfunc newImportContext() *importContext {\n\treturn &importContext{\n\t\tcodes: map[common.Hash][]byte{\n\t\t\tcommon.Keccak256([]byte{}): {},\n\t\t},\n\t}\n}\n\nfunc (c *importContext) addCode(code []byte) {\n\tc.codes[common.Keccak256(code)] = code\n}\n\nfunc (c *importContext) setBlock(block uint64) {\n\tc.currentBlock = block\n}\n\nfunc (c *importContext) setBlockHash(hash common.Hash) {\n\tc.currentBlockHash = hash\n\tc.currentBlockHashFound = true\n}\n\nfunc (c *importContext) setAccount(address common.Address) {\n\tc.currentAccount = address\n}\n\nfunc (c *importContext) deleteAccount() {\n\tc.currentUpdate.AppendDeleteAccount(c.currentAccount)\n}\n\nfunc (c *importContext) setBalance(balance common.Balance) {\n\tc.currentUpdate.AppendBalanceUpdate(c.currentAccount, balance)\n}\n\nfunc (c *importContext) setNonce(nonce common.Nonce) {\n\tc.currentUpdate.AppendNonceUpdate(c.currentAccount, nonce)\n}\n\nfunc (c *importContext) setCode(hash common.Hash) error {\n\tcode, found := c.codes[hash]\n\tif !found {\n\t\treturn fmt.Errorf(\"missing code for hash %v in input file\", hash)\n\t}\n\tc.currentUpdate.AppendCodeUpdate(c.currentAccount, code)\n\treturn nil\n}\n\nfunc (c *importContext) setSlot(key common.Key, value common.Value) {\n\tc.currentUpdate.AppendSlotUpdate(c.currentAccount, key, value)\n}\n\nfunc (c *importContext) deleteSlot(key common.Key) {\n\tc.currentUpdate.AppendSlotUpdate(c.currentAccount, key, common.Value{})\n}\n\nfunc (c *importContext) finishCurrentBlock(archive archive.Archive, live state.LiveDB) error {\n\tif c.currentUpdate.IsEmpty() {\n\t\treturn nil\n\t}\n\tif !c.currentBlockHashFound {\n\t\treturn fmt.Errorf(\"input format error: no hash for block %d\", c.currentBlock)\n\t}\n\thints, err := live.Apply(c.currentBlock, c.currentUpdate)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := archive.Add(c.currentBlock, c.currentUpdate, hints); err != nil {\n\t\treturn err\n\t}\n\thints.Release()\n\thash, err := archive.GetHash(c.currentBlock)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif hash != c.currentBlockHash {\n\t\treturn fmt.Errorf(\"invalid hash for block %d: from input %x, restored hash %x\", c.currentBlock, c.currentBlockHash, hash)\n\t}\n\n\tc.currentUpdate = common.Update{}\n\tc.currentBlockHashFound = false\n\treturn nil\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/io/archive.go b/go/database/mpt/io/archive.go
--- a/go/database/mpt/io/archive.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/io/archive.go	(date 1717067063209)
@@ -12,6 +12,7 @@
 
 import (
 	"bytes"
+	"context"
 	"encoding/binary"
 	"errors"
 	"fmt"
@@ -54,7 +55,7 @@
 
 const archiveFormatVersion = byte(1)
 
-func ExportArchive(directory string, out io.Writer) error {
+func ExportArchive(directory string, out io.Writer, ctx context.Context) error {
 
 	info, err := CheckMptDirectoryAndGetInfo(directory)
 	if err != nil {
Index: go/database/mpt/io/live_test.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage io\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt\"\n)\n\nfunc TestIO_ExportAndImportAsLiveDb(t *testing.T) {\n\tgenesis, hash := exportExampleState(t)\n\n\tbuffer := bytes.NewBuffer(genesis)\n\ttargetDir := t.TempDir()\n\tif err := ImportLiveDb(targetDir, buffer); err != nil {\n\t\tt.Fatalf(\"failed to import DB: %v\", err)\n\t}\n\n\tif err := mpt.VerifyFileLiveTrie(targetDir, mpt.S5LiveConfig, nil); err != nil {\n\t\tt.Fatalf(\"verification of imported DB failed: %v\", err)\n\t}\n\n\tdb, err := mpt.OpenGoFileState(targetDir, mpt.S5LiveConfig, 1024)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to open recovered DB: %v\", err)\n\t}\n\tdefer db.Close()\n\n\tif exists, err := db.Exists(common.Address{1}); err != nil || !exists {\n\t\tt.Fatalf(\"restored DB does not contain account 1\")\n\t}\n\tif exists, err := db.Exists(common.Address{2}); err != nil || !exists {\n\t\tt.Fatalf(\"restored DB does not contain account 2\")\n\t}\n\n\tif got, err := db.GetHash(); err != nil || got != hash {\n\t\tt.Fatalf(\"restored DB failed to reproduce same hash\\nwanted %x\\n   got %x\\n   err %v\", hash, got, err)\n\t}\n}\n\nfunc TestIO_ExportAndImportAsArchive(t *testing.T) {\n\tgenesis, hash := exportExampleState(t)\n\n\tbuffer := bytes.NewBuffer(genesis)\n\ttargetDir := t.TempDir()\n\tgenesisBlock := uint64(12)\n\tif err := InitializeArchive(targetDir, buffer, genesisBlock); err != nil {\n\t\tt.Fatalf(\"failed to import DB: %v\", err)\n\t}\n\n\tif err := mpt.VerifyArchive(targetDir, mpt.S5ArchiveConfig, nil); err != nil {\n\t\tt.Fatalf(\"verification of imported DB failed: %v\", err)\n\t}\n\n\tdb, err := mpt.OpenArchiveTrie(targetDir, mpt.S5ArchiveConfig, 1024)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to open recovered DB: %v\", err)\n\t}\n\tdefer db.Close()\n\n\theight, empty, err := db.GetBlockHeight()\n\tif err != nil || empty || height != genesisBlock {\n\t\tt.Fatalf(\"invalid block height, wanted %d, got %d, empty %t, err %v\", genesisBlock, height, empty, err)\n\t}\n\n\tif exists, err := db.Exists(genesisBlock, common.Address{1}); err != nil || !exists {\n\t\tt.Fatalf(\"restored DB does not contain account 1\")\n\t}\n\tif exists, err := db.Exists(genesisBlock, common.Address{2}); err != nil || !exists {\n\t\tt.Fatalf(\"restored DB does not contain account 2\")\n\t}\n\n\tif got, err := db.GetHash(genesisBlock); err != nil || got != hash {\n\t\tt.Fatalf(\"restored DB failed to reproduce same hash\\nwanted %x\\n   got %x\\n   err %v\", hash, got, err)\n\t}\n\n\tfor i := uint64(0); i < genesisBlock; i++ {\n\t\tif got, err := db.GetHash(i); err != nil || got != mpt.EmptyNodeEthereumHash {\n\t\t\tt.Fatalf(\"invalid hash for pre-genesis block %d\\nwanted %x\\n   got %x\\n   err %v\", i, mpt.EmptyNodeEthereumHash, got, err)\n\t\t}\n\t}\n}\n\nfunc exportExampleState(t *testing.T) ([]byte, common.Hash) {\n\tt.Helper()\n\tsourceDir := t.TempDir()\n\n\t// Create a small LiveDB.\n\tdb, err := mpt.OpenGoFileState(sourceDir, mpt.S5LiveConfig, 1024)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create test DB: %v\", err)\n\t}\n\n\taddr1 := common.Address{1}\n\taddr2 := common.Address{2}\n\tkey1 := common.Key{1}\n\tkey2 := common.Key{2}\n\tvalue1 := common.Value{1}\n\tvalue2 := common.Value{2}\n\terr = errors.Join(\n\t\t// First account, with code.\n\t\tdb.SetNonce(addr1, common.ToNonce(1)),\n\t\tdb.SetBalance(addr1, common.Balance{12}),\n\t\tdb.SetStorage(addr1, key1, value1),\n\t\tdb.SetCode(addr1, []byte(\"some_code\")),\n\t\t// Second account, without code.\n\t\tdb.SetNonce(addr2, common.ToNonce(2)),\n\t\tdb.SetBalance(addr2, common.Balance{14}),\n\t\tdb.SetStorage(addr2, key1, value1),\n\t\tdb.SetStorage(addr2, key2, value2),\n\t)\n\n\tif err != nil {\n\t\tt.Fatalf(\"failed to seed test DB: %v\", err)\n\t}\n\n\thash, err := db.GetHash()\n\tif err != nil {\n\t\tt.Fatalf(\"failed to fetch hash from DB: %v\", err)\n\t}\n\tif err := db.Close(); err != nil {\n\t\tt.Fatalf(\"failed to close DB: %v\", err)\n\t}\n\n\t// Export database to buffer.\n\tvar buffer bytes.Buffer\n\tif err := Export(sourceDir, &buffer); err != nil {\n\t\tt.Fatalf(\"failed to export DB: %v\", err)\n\t}\n\n\treturn buffer.Bytes(), hash\n}\n\nfunc TestImport_ImportIntoNonEmptyTargetDirectoryFails(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := os.WriteFile(dir+string(os.PathSeparator)+\"test.txt\", nil, 0700); err != nil {\n\t\tt.Fatalf(\"failed to create file: %v\", err)\n\t}\n\n\tif err := ImportLiveDb(dir, nil); err == nil || !strings.Contains(err.Error(), \"is not empty\") {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestInitializeArchive_ImportIntoNonEmptyTargetDirectoryFails(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := os.WriteFile(dir+string(os.PathSeparator)+\"test.txt\", nil, 0700); err != nil {\n\t\tt.Fatalf(\"failed to create file: %v\", err)\n\t}\n\n\tif err := InitializeArchive(dir, nil, 0); err == nil || !strings.Contains(err.Error(), \"is not empty\") {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestCheckEmptyDirectory_PassesIfEmpty(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := checkEmptyDirectory(dir); err != nil {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestCheckEmptyDirectory_FailsIfDirectoryDoesNotExist(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := checkEmptyDirectory(dir + string(os.PathSeparator) + \"sub\"); err == nil {\n\t\tt.Errorf(\"test expected to produce an error\")\n\t}\n}\n\nfunc TestCheckEmptyDirectory_FailsIfDirectoryIsAFile(t *testing.T) {\n\tdir := t.TempDir()\n\tfile := dir + string(os.PathSeparator) + \"test.txt\"\n\tif err := os.WriteFile(file, nil, 0700); err != nil {\n\t\tt.Fatalf(\"failed to create file: %v\", err)\n\t}\n\tif err := checkEmptyDirectory(file); err == nil {\n\t\tt.Errorf(\"test expected to produce an error\")\n\t}\n}\n\nfunc TestCheckEmptyDirectory_FailsIfDirectoryContainsAFile(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := os.WriteFile(dir+string(os.PathSeparator)+\"test.txt\", nil, 0700); err != nil {\n\t\tt.Fatalf(\"failed to create file: %v\", err)\n\t}\n\tif err := checkEmptyDirectory(dir); err == nil || !strings.Contains(err.Error(), \"is not empty\") {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n}\n\nfunc TestCheckEmptyDirectory_FailsIfDirectoryContainsADirectory(t *testing.T) {\n\tdir := t.TempDir()\n\tif err := os.Mkdir(dir+string(os.PathSeparator)+\"sub\", 0700); err != nil {\n\t\tt.Fatalf(\"failed to create sub-directory: %v\", err)\n\t}\n\tif err := checkEmptyDirectory(dir); err == nil || !strings.Contains(err.Error(), \"is not empty\") {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/io/live_test.go b/go/database/mpt/io/live_test.go
--- a/go/database/mpt/io/live_test.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/io/live_test.go	(date 1717066858230)
@@ -12,10 +12,14 @@
 
 import (
 	"bytes"
+	"context"
 	"errors"
+	"fmt"
 	"os"
+	"os/signal"
 	"strings"
 	"testing"
+	"time"
 
 	"github.com/Fantom-foundation/Carmen/go/common"
 	"github.com/Fantom-foundation/Carmen/go/database/mpt"
@@ -211,3 +215,28 @@
 		t.Errorf("unexpected error: %v", err)
 	}
 }
+
+func TestExport_SigIntIsTrapped(t *testing.T) {
+	fmt.Println("start")
+	ctx := context.Background()
+
+	// trap Ctrl+C and call cancel on the context
+	ctx, cancel := context.WithCancel(ctx)
+	c := make(chan os.Signal, 1)
+	signal.Notify(c, os.Interrupt)
+	defer func() {
+		signal.Stop(c)
+		cancel()
+	}()
+	go func() {
+		select {
+		case <-c:
+			fmt.Println("hi")
+			cancel()
+			os.Exit(2)
+		case <-ctx.Done():
+		}
+	}()
+
+	time.Sleep(3 * time.Hour)
+}
Index: go/database/mpt/io/live.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage io\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt\"\n)\n\n// This file provides a pair of import and export functions capable of\n// serializing the content of a LiveDB into a single, payload-only data\n// blob with build-in consistency check which can be utilized for safely\n// transferring state information between systems.\n//\n// Format:\n//\n//  file  ::= <magic-number> <version> [<hash>]+ [<code>]* [<entry>]*\n//  hash  ::= 'H' <1-byte hash type identifier> <state-hash>\n//  code  ::= 'C' <2-byte big-endian code length> <code>\n//  entry ::= 'A' <address> <balance> <nonce> <code-hash>\n//          | 'S' <key> <value>\n//\n// All values belong to the account preceding it. The produced data stream\n// may be further compressed (e.g. using Gzip) to reduce its size.\n\nvar stateMagicNumber []byte = []byte(\"Fantom-World-State\")\n\nconst formatVersion = byte(1)\n\ntype HashType byte\n\n// So far there is only one hash type supported, the Ethereum hash. But for\n// future situations we might want to support different hash types, like the\n// S4 hash definition. Thus this enum is introduced as a placeholder.\nconst (\n\tEthereumHash = HashType(0)\n)\n\n// Export opens a LiveDB instance retained in the given directory and writes\n// its content to the given output writer. The result contains all the\n// information required by the Import function below to reconstruct the full\n// state of the LiveDB.\nfunc Export(directory string, out io.Writer) error {\n\n\tinfo, err := CheckMptDirectoryAndGetInfo(directory)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error in input directory: %v\", err)\n\t}\n\n\tif info.Config.Name != mpt.S5LiveConfig.Name {\n\t\treturn fmt.Errorf(\"can only support export of LiveDB instances, found %v in directory\", info.Mode)\n\t}\n\n\tdb, err := mpt.OpenGoFileState(directory, info.Config, mpt.DefaultMptStateCapacity)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open LiveDB: %v\", err)\n\t}\n\tdefer db.Close()\n\n\t// Start with the magic number.\n\tif _, err := out.Write(stateMagicNumber); err != nil {\n\t\treturn err\n\t}\n\n\t// Add a version number.\n\tif _, err := out.Write([]byte{formatVersion}); err != nil {\n\t\treturn err\n\t}\n\n\t// Continue with the full state hash.\n\thash, err := db.GetHash()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, err := out.Write([]byte{byte('H'), byte(EthereumHash)}); err != nil {\n\t\treturn err\n\t}\n\tif _, err := out.Write(hash[:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Write out codes.\n\tcodes, err := db.GetCodes()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to retrieve codes: %v\", err)\n\t}\n\tif err := writeCodes(codes, out); err != nil {\n\t\treturn err\n\t}\n\n\t// Write out all accounts and values.\n\tvisitor := exportVisitor{out: out}\n\tif err := db.Visit(&visitor); err != nil || visitor.err != nil {\n\t\treturn fmt.Errorf(\"failed exporting content: %v\", errors.Join(err, visitor.err))\n\t}\n\n\treturn nil\n}\n\n// ImportLiveDb creates a fresh StateDB in the given directory and fills it\n// with the content read from the given reader.\nfunc ImportLiveDb(directory string, in io.Reader) error {\n\t_, _, err := runImport(directory, in, mpt.S5LiveConfig)\n\treturn err\n}\n\n// InitializeArchive creates a fresh Archive in the given directory containing\n// the state read from the input stream at the given block. All states before\n// the given block are empty.\nfunc InitializeArchive(directory string, in io.Reader, block uint64) (err error) {\n\t// The import creates a live-DB state that initializes the Archive.\n\troot, hash, err := runImport(directory, in, mpt.S5ArchiveConfig)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Seal the data by marking the content as immutable.\n\tforestFile := directory + string(os.PathSeparator) + \"forest.json\"\n\tmetaData, err := os.ReadFile(forestFile)\n\tif err != nil {\n\t\treturn err\n\t}\n\tmetaData = []byte(strings.Replace(string(metaData), \"\\\"Mutable\\\":true\", \"\\\"Mutable\\\":false\", 1))\n\tif err := os.WriteFile(forestFile, metaData, 0600); err != nil {\n\t\treturn err\n\t}\n\n\t// Create a root file listing block roots.\n\troots := make([]mpt.Root, block+1)\n\tfor i := uint64(0); i < block; i++ {\n\t\troots[i] = mpt.Root{\n\t\t\tNodeRef: mpt.NewNodeReference(mpt.EmptyId()),\n\t\t\tHash:    mpt.EmptyNodeEthereumHash,\n\t\t}\n\t}\n\troots[block] = mpt.Root{\n\t\tNodeRef: mpt.NewNodeReference(root),\n\t\tHash:    hash,\n\t}\n\tif err := mpt.StoreRoots(directory+string(os.PathSeparator)+\"roots.dat\", roots); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc runImport(directory string, in io.Reader, config mpt.MptConfig) (root mpt.NodeId, hash common.Hash, err error) {\n\t// check that the destination directory is an empty directory\n\tif err := checkEmptyDirectory(directory); err != nil {\n\t\treturn root, hash, err\n\t}\n\n\t// Start by checking the magic number.\n\tbuffer := make([]byte, len(stateMagicNumber))\n\tif _, err := io.ReadFull(in, buffer); err != nil {\n\t\treturn root, hash, err\n\t} else if !bytes.Equal(buffer, stateMagicNumber) {\n\t\treturn root, hash, fmt.Errorf(\"invalid format, wrong magic number\")\n\t}\n\n\t// Check the version number.\n\tif _, err := io.ReadFull(in, buffer[0:1]); err != nil {\n\t\treturn root, hash, err\n\t} else if buffer[0] != formatVersion {\n\t\treturn root, hash, fmt.Errorf(\"invalid format, unsupported version\")\n\t}\n\n\t// Create a state.\n\tdb, err := mpt.OpenGoFileState(directory, config, mpt.DefaultMptStateCapacity)\n\tif err != nil {\n\t\treturn root, hash, fmt.Errorf(\"failed to create empty state: %v\", err)\n\t}\n\tdefer func() {\n\t\terr = errors.Join(err, db.Close())\n\t}()\n\n\tvar (\n\t\taddr    common.Address\n\t\tkey     common.Key\n\t\tvalue   common.Value\n\t\tbalance common.Balance\n\t\tnonce   common.Nonce\n\t)\n\n\t// Read the rest and build the state.\n\tbuffer = buffer[0:1]\n\tcodes := map[common.Hash][]byte{\n\t\tcommon.Keccak256([]byte{}): {},\n\t}\n\n\tcounter := 0\n\n\thashFound := false\n\tvar stateHash common.Hash\n\tfor {\n\t\t// Update hashes periodically to avoid running out of memory\n\t\t// for nodes with dirty hashes.\n\t\tcounter++\n\t\tif (counter % 100_000) == 0 {\n\t\t\tif _, err := db.GetHash(); err != nil {\n\t\t\t\treturn root, hash, fmt.Errorf(\"failed to update hashes: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\tif _, err := io.ReadFull(in, buffer); err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tif !hashFound {\n\t\t\t\t\treturn root, hash, fmt.Errorf(\"file does not contain a compatible state hash\")\n\t\t\t\t}\n\t\t\t\t// Check the final hash.\n\t\t\t\thash, err := db.GetHash()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn root, hash, err\n\t\t\t\t}\n\t\t\t\tif stateHash != hash {\n\t\t\t\t\treturn root, hash, fmt.Errorf(\"failed to reproduce valid state, hashes do not match\")\n\t\t\t\t}\n\t\t\t\treturn db.GetRootId(), hash, nil\n\t\t\t}\n\t\t\treturn root, hash, err\n\t\t}\n\t\tswitch buffer[0] {\n\t\tcase 'A':\n\t\t\tif _, err := io.ReadFull(in, addr[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, balance[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif err := db.SetBalance(addr, balance); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, nonce[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif err := db.SetNonce(addr, nonce); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, hash[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif code, found := codes[hash]; found {\n\t\t\t\tif err := db.SetCode(addr, code); err != nil {\n\t\t\t\t\treturn root, hash, err\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn root, hash, fmt.Errorf(\"missing code with hash %x for account %x\", hash[:], addr[:])\n\t\t\t}\n\n\t\tcase 'S':\n\t\t\tif _, err := io.ReadFull(in, key[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif _, err := io.ReadFull(in, value[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif err := db.SetStorage(addr, key, value); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\n\t\tcase 'C':\n\t\t\tcode, err := readCode(in)\n\t\t\tif err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tcodes[common.Keccak256(code)] = code\n\t\tcase 'H':\n\t\t\tif _, err := io.ReadFull(in, buffer); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\thashType := HashType(buffer[0])\n\t\t\thash := common.Hash{}\n\t\t\tif _, err := io.ReadFull(in, hash[:]); err != nil {\n\t\t\t\treturn root, hash, err\n\t\t\t}\n\t\t\tif hashType == EthereumHash {\n\t\t\t\tstateHash = hash\n\t\t\t\thashFound = true\n\t\t\t}\n\t\tdefault:\n\t\t\treturn root, hash, fmt.Errorf(\"format error encountered, unexpected token type: %c\", buffer[0])\n\t\t}\n\t}\n}\n\n// exportVisitor is an internal utility used by the Export function to write\n// account and value node information to a given output writer.\ntype exportVisitor struct {\n\tout io.Writer\n\terr error\n}\n\nfunc (e *exportVisitor) Visit(node mpt.Node, _ mpt.NodeInfo) mpt.VisitResponse {\n\tswitch n := node.(type) {\n\tcase *mpt.AccountNode:\n\t\taddr := n.Address()\n\t\tinfo := n.Info()\n\t\tif _, err := e.out.Write([]byte{byte('A')}); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(addr[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(info.Balance[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(info.Nonce[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(info.CodeHash[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\tcase *mpt.ValueNode:\n\t\tkey := n.Key()\n\t\tvalue := n.Value()\n\t\tif _, err := e.out.Write([]byte{byte('S')}); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(key[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t\tif _, err := e.out.Write(value[:]); err != nil {\n\t\t\te.err = err\n\t\t\treturn mpt.VisitResponseAbort\n\t\t}\n\t}\n\treturn mpt.VisitResponseContinue\n}\n\nfunc checkEmptyDirectory(directory string) error {\n\tfile, err := os.Open(directory)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open directory %s: %w\", directory, err)\n\t}\n\tdefer file.Close()\n\tstate, err := file.Stat()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open file information for %s: %w\", directory, err)\n\t}\n\tif !state.IsDir() {\n\t\treturn fmt.Errorf(\"the path `%s` does not point to a directory\", directory)\n\t}\n\t_, err = file.Readdirnames(1)\n\tif err == nil {\n\t\treturn fmt.Errorf(\"directory `%s` is not empty\", directory)\n\t}\n\tif !errors.Is(err, io.EOF) {\n\t\treturn fmt.Errorf(\"failed to list content of directory `%s`: %w\", directory, err)\n\t}\n\treturn nil\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/io/live.go b/go/database/mpt/io/live.go
--- a/go/database/mpt/io/live.go	(revision 67008e3801f9718da0284207e90d72b35ca294e5)
+++ b/go/database/mpt/io/live.go	(date 1717067297171)
@@ -12,6 +12,7 @@
 
 import (
 	"bytes"
+	"context"
 	"errors"
 	"fmt"
 	"io"
@@ -55,7 +56,7 @@
 // its content to the given output writer. The result contains all the
 // information required by the Import function below to reconstruct the full
 // state of the LiveDB.
-func Export(directory string, out io.Writer) error {
+func Export(directory string, out io.Writer, ctx context.Context) error {
 
 	info, err := CheckMptDirectoryAndGetInfo(directory)
 	if err != nil {
@@ -66,7 +67,7 @@
 		return fmt.Errorf("can only support export of LiveDB instances, found %v in directory", info.Mode)
 	}
 
-	db, err := mpt.OpenGoFileState(directory, info.Config, mpt.DefaultMptStateCapacity)
+	db, err := mpt.OpenGoFileStateWithContext(directory, info.Config, mpt.DefaultMptStateCapacity, ctx)
 	if err != nil {
 		return fmt.Errorf("failed to open LiveDB: %v", err)
 	}
