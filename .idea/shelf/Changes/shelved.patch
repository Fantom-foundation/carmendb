Index: go/database/mpt/verification_test.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage mpt\n\nimport (\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/backend/stock\"\n\t\"github.com/Fantom-foundation/Carmen/go/backend/stock/file\"\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"go.uber.org/mock/gomock\"\n)\n\nvar forestFiles = []string{\n\t\"\",\n\t\"accounts\",\n\t\"accounts/freelist.dat\",\n\t\"accounts/meta.json\",\n\t\"accounts/values.dat\",\n\t\"branches\",\n\t\"branches/freelist.dat\",\n\t\"branches/meta.json\",\n\t\"branches/values.dat\",\n\t\"extensions\",\n\t\"extensions/freelist.dat\",\n\t\"extensions/meta.json\",\n\t\"extensions/values.dat\",\n\t\"values\",\n\t\"values/freelist.dat\",\n\t\"values/meta.json\",\n\t\"values/values.dat\",\n}\n\nfunc TestVerification_VerifyValidForest(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err != nil {\n\t\t\tt.Errorf(\"found unexpected error in fresh forest: %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestVerification_VerificationObserverIsKeptUpdatedOnEvents(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\n\t\tctrl := gomock.NewController(t)\n\t\tobserver := NewMockVerificationObserver(ctrl)\n\n\t\tgomock.InOrder(\n\t\t\tobserver.EXPECT().StartVerification(),\n\t\t\tobserver.EXPECT().Progress(gomock.Any()).MinTimes(1),\n\t\t\tobserver.EXPECT().EndVerification(nil),\n\t\t)\n\n\t\tif err := VerifyFileForest(dir, config, roots, observer); err != nil {\n\t\t\tt.Errorf(\"found unexpected error in fresh forest: %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestVerification_MissingFileIsDetected(t *testing.T) {\n\tfor _, file := range forestFiles {\n\t\tt.Run(file, func(t *testing.T) {\n\t\t\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t\t\tif err := os.RemoveAll(dir + \"/\" + file); err != nil {\n\t\t\t\t\tt.Fatalf(\"failed to delete file %v: %v\", file, err)\n\t\t\t\t}\n\t\t\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\t\t\tt.Errorf(\"The missing file %v should have been detected\", file)\n\t\t\t\t}\n\t\t\t})\n\t\t})\n\t}\n}\n\nfunc TestVerification_ModifiedFileIsDetected(t *testing.T) {\n\tfor _, file := range forestFiles {\n\t\tt.Run(file, func(t *testing.T) {\n\t\t\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t\t\tpath := dir + \"/\" + file\n\t\t\t\tif isDirectory(path) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tdata, err := os.ReadFile(path)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"failed to read file %v: %v\", path, err)\n\t\t\t\t}\n\t\t\t\tif len(data) == 0 {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\t// Modify the content of the file a lot since some files contain\n\t\t\t\t// unused data that is not covered by the validation. Finer-grained\n\t\t\t\t// changes are checked below.\n\t\t\t\tfor i := range data {\n\t\t\t\t\tdata[i]++\n\t\t\t\t}\n\t\t\t\tif err := os.WriteFile(path, data, 0600); err != nil {\n\t\t\t\t\tt.Fatalf(\"failed to write modified file content: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\t\t\tt.Errorf(\"Modified file %v should have been detected\", file)\n\t\t\t\t}\n\t\t\t})\n\t\t})\n\t}\n}\n\nfunc TestVerification_ModifiedRootIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, encoder, _, _ := getEncoder(config)\n\n\t\troot := NewNodeReference(EmptyId())\n\t\tfor i := 0; i < len(roots); i++ {\n\t\t\tif roots[i].NodeRef.Id().IsBranch() {\n\t\t\t\troot = roots[i].NodeRef\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !root.Id().IsBranch() {\n\t\t\tt.Fatalf(\"no root referencing a branch found\")\n\t\t}\n\n\t\tstock, err := file.OpenStock[uint64](encoder, dir+\"/branches\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open stock\")\n\t\t}\n\n\t\tnode, err := stock.Get(root.Id().Index())\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to load node from stock: %v\", err)\n\t\t}\n\n\t\ta := 0\n\t\tb := 1\n\t\tfor node.children[b].Id().IsEmpty() {\n\t\t\tb++\n\t\t}\n\t\tnode.children[a], node.children[b] = node.children[b], node.children[a]\n\t\tnode.hashes[a], node.hashes[b] = node.hashes[b], node.hashes[a]\n\n\t\tif err := stock.Set(root.Id().Index(), node); err != nil {\n\t\t\tt.Fatalf(\"failed to update node: %v\", err)\n\t\t}\n\n\t\tif err := stock.Close(); err != nil {\n\t\t\tt.Fatalf(\"failed to close stock: %v\", err)\n\t\t}\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified root node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountBalanceModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.info.Balance[2]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountNonceModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.info.Nonce[2]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountCodeHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.info.CodeHash[2]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountStorageModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.storage = NewNodeReference(ValueId(123456789)) // invalid in test forest\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountNodeHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithNode {\n\t\t\treturn\n\t\t}\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.hash[3]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_AccountStorageHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithParent {\n\t\t\treturn\n\t\t}\n\t\tencoder, _, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/accounts\", encoder, func(node *AccountNode) {\n\t\t\tnode.storageHash[3]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_BranchChildIdModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, encoder, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/branches\", encoder, func(node *BranchNode) {\n\t\t\tnode.children[8] = NewNodeReference(ValueId(123456789)) // does not exist in test forest\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_BranchNodeHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithNode {\n\t\t\treturn\n\t\t}\n\t\t_, encoder, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/branches\", encoder, func(node *BranchNode) {\n\t\t\tnode.hash[4]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_BranchChildHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithParent {\n\t\t\treturn\n\t\t}\n\t\t_, encoder, _, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/branches\", encoder, func(node *BranchNode) {\n\t\t\tfor i, child := range node.children {\n\t\t\t\tif !child.Id().IsEmpty() {\n\t\t\t\t\tnode.hashes[i][4]++\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ExtensionPathModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, _, encoder, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/extensions\", encoder, func(node *ExtensionNode) {\n\t\t\tnode.path.path[0] = ^node.path.path[0]\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ExtensionNextModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, _, encoder, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/extensions\", encoder, func(node *ExtensionNode) {\n\t\t\tnode.next = NewNodeReference(BranchId(123456789))\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ExtensionNodeHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithNode {\n\t\t\treturn\n\t\t}\n\t\t_, _, encoder, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/extensions\", encoder, func(node *ExtensionNode) {\n\t\t\tnode.hash[24]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ExtensionNextHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithParent {\n\t\t\treturn\n\t\t}\n\t\t_, _, encoder, _ := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/extensions\", encoder, func(node *ExtensionNode) {\n\t\t\tnode.nextHash[24]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ValueKeyModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, _, _, encoder := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/values\", encoder, func(node *ValueNode) {\n\t\t\tnode.key[5]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ValueModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_, _, _, encoder := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/values\", encoder, func(node *ValueNode) {\n\t\t\tnode.value[12]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_ValueNodeHashModificationIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif config.HashStorageLocation != HashStoredWithNode {\n\t\t\treturn\n\t\t}\n\t\t_, _, _, encoder := getEncoder(config)\n\n\t\tmodifyNode(t, dir+\"/values\", encoder, func(node *ValueNode) {\n\t\t\tnode.hash[12]++\n\t\t})\n\n\t\tif err := VerifyFileForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"Modified node should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_MissingCodeHashInCodeFileIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\terr := VerifyCodesAndForest(dir, config, roots, NilVerificationObserver{})\n\t\tif err == nil {\n\t\t\tt.Errorf(\"missing hash in code file should have been detected\")\n\t\t\treturn\n\t\t}\n\t\tgot := err.Error()\n\t\twant := fmt.Sprintf(\"hash %x is missing in code file\", common.Keccak256([]byte{1}))\n\t\tif !strings.Contains(got, want) {\n\t\t\tt.Errorf(\"unexpected error, got: %v, want: %v\", got, want)\n\t\t}\n\t})\n}\n\nfunc TestVerification_DifferentHashInCodeFileIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\ttestHash := common.Keccak256([]byte{1})\n\t\tbyteCode := []byte{2}\n\t\tcodes := map[common.Hash][]byte{\n\t\t\ttestHash: byteCode,\n\t\t}\n\t\tif err := writeCodes(codes, filepath.Join(dir, \"codes.dat\")); err != nil {\n\t\t\tt.Fatalf(\"failed to write code file\")\n\t\t}\n\n\t\terr := VerifyCodesAndForest(dir, config, roots, NilVerificationObserver{})\n\t\tif err == nil {\n\t\t\tt.Errorf(\"different hash in code file should have been detected\")\n\t\t\treturn\n\t\t}\n\n\t\tgot := err.Error()\n\t\twant := fmt.Sprintf(\"unexpected code hash, got: %x want: %x\", common.Keccak256(byteCode), testHash)\n\n\t\tif !strings.Contains(got, want) {\n\t\t\tt.Errorf(\"unexpected error, got: %v, want: %v\", got, want)\n\t\t}\n\t})\n}\n\nfunc TestVerification_ExtraCodeHashInCodeFileIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tctrl := gomock.NewController(t)\n\t\tobserver := NewMockVerificationObserver(ctrl)\n\n\t\ttestHash1 := common.Keccak256([]byte{1})\n\t\ttestHash2 := common.Keccak256([]byte{2})\n\t\tcodes := map[common.Hash][]byte{\n\t\t\ttestHash1: {1},\n\t\t\ttestHash2: {2},\n\t\t}\n\n\t\tvar triggered bool\n\t\tobserver.EXPECT().StartVerification()\n\t\tobserver.EXPECT().EndVerification(nil)\n\t\tobserver.EXPECT().Progress(gomock.Any()).Do(func(msg string) {\n\t\t\tif strings.Contains(msg, fmt.Sprintf(\"Contract %x is not referenced\", testHash2)) {\n\t\t\t\ttriggered = true\n\t\t\t}\n\t\t}).AnyTimes()\n\n\t\tif err := writeCodes(codes, dir+\"/codes.dat\"); err != nil {\n\t\t\tt.Fatalf(\"failed to write code file\")\n\t\t}\n\n\t\tif err := VerifyCodesAndForest(dir, config, roots, observer); err != nil {\n\t\t\tt.Errorf(\"found unexpected error in fresh forest: %v\", err)\n\t\t}\n\n\t\tif !triggered {\n\t\t\tt.Errorf(\"extra hash in code file should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_UnreadableCodesReturnError(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t// create code file\n\t\tif err := writeCodes(nil, filepath.Join(dir, \"codes.dat\")); err != nil {\n\t\t\tt.Fatalf(\"failed to create codes file: %v\", err)\n\t\t}\n\t\t// corrupt it\n\t\tf, err := os.OpenFile(filepath.Join(dir, \"codes.dat\"), os.O_APPEND|os.O_WRONLY, os.ModeAppend)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to open codes file: %v\", err)\n\t\t}\n\t\tif _, err = f.Write([]byte{1}); err != nil {\n\t\t\tt.Fatalf(\"failed to open write to codes file: %v\", err)\n\t\t}\n\t\tif err = f.Close(); err != nil {\n\t\t\tt.Fatalf(\"failed to close codes file: %v\", err)\n\t\t}\n\n\t\tif err = VerifyCodesAndForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"unreadable code file should have been detected\")\n\t\t\treturn\n\t\t}\n\n\t\tgot := err\n\t\twant := io.ErrUnexpectedEOF\n\t\tif !errors.Is(got, want) {\n\t\t\tt.Errorf(\"unexpected error, got: %v, want: %v\", got, want)\n\t\t}\n\t})\n}\n\nfunc TestVerification_PassingNilAsObserverDoesNotFail(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\t_ = VerifyCodesAndForest(dir, config, roots, nil)\n\t})\n}\n\nfunc TestVerifyFileForest_PassingNilAsObserverDoesNotFail(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\tif err := VerifyFileForest(dir, config, roots, nil); err != nil {\n\t\t\tt.Errorf(\"found unexpected error in verification: %v\", err)\n\t\t}\n\t})\n}\n\nfunc TestVerification_DifferentExtraHashInCodeFileIsDetected(t *testing.T) {\n\trunVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {\n\t\ttestHash := common.Keccak256([]byte{3})\n\t\tcodes := map[common.Hash][]byte{\n\t\t\ttestHash: {2},\n\t\t}\n\t\tif err := writeCodes(codes, filepath.Join(dir, \"codes.dat\")); err != nil {\n\t\t\tt.Fatalf(\"failed to write code file\")\n\t\t}\n\n\t\tif err := VerifyCodesAndForest(dir, config, roots, NilVerificationObserver{}); err == nil {\n\t\t\tt.Errorf(\"different extra hash in code file should have been detected\")\n\t\t}\n\t})\n}\n\nfunc TestVerification_HashesOfEmbeddedNodesAreIgnored(t *testing.T) {\n\t// Construct an MPT with some embedded nodes. For this we need some keys\n\t// with their hashes sharing a long common prefix. The hashes of the\n\t// following keys have a 4-byte long common prefix.\n\tvar key1, key2 common.Key\n\tdata, _ := hex.DecodeString(\"965866864f3cc23585ad48a3b4b061c5e1d5a471dbb2360538029046ac528d85\")\n\tcopy(key1[:], data)\n\tdata, _ = hex.DecodeString(\"c1bb1e5ab6acf1bef1a125f3d60e0941b9a8624288ffd67282484c25519f9e65\")\n\tcopy(key2[:], data)\n\n\tvar v1 common.Value\n\tv1[len(v1)-1] = 1\n\n\tdir := t.TempDir()\n\tforestConfig := ForestConfig{Mode: Mutable, CacheCapacity: 1024}\n\tforest, err := OpenFileForest(dir, S5LiveConfig, forestConfig)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to start empty forest: %v\", err)\n\t}\n\n\troot := NewNodeReference(EmptyId())\n\n\taddr := common.Address{}\n\troot, err = forest.SetAccountInfo(&root, addr, AccountInfo{Nonce: common.ToNonce(1)})\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create account: %v\", err)\n\t}\n\n\troot, err = forest.SetValue(&root, addr, key1, v1)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to set value for key1: %v\", err)\n\t}\n\n\troot, err = forest.SetValue(&root, addr, key2, v1)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to set value for key2: %v\", err)\n\t}\n\n\thash, _, err := forest.updateHashesFor(&root)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to compute hash for trie: %v\", err)\n\t}\n\n\tif err := forest.Close(); err != nil {\n\t\tt.Fatalf(\"failed to close trie: %v\", err)\n\t}\n\n\t// Run the verification for the trie (which includes embedded nodes).\n\tif err := VerifyFileForest(dir, S5LiveConfig, []Root{{root, hash}}, NilVerificationObserver{}); err != nil {\n\t\tt.Errorf(\"Unexpected verification error: %v\", err)\n\t}\n}\n\nfunc runVerificationTest(t *testing.T, verify func(t *testing.T, dir string, config MptConfig, roots []Root)) {\n\tt.Helper()\n\tfor _, config := range allMptConfigs {\n\t\tconfig := config\n\t\tt.Run(config.Name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tt.Helper()\n\t\t\tdir := t.TempDir()\n\t\t\troots, err := fillTestForest(dir, config)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to create example forest: %v\", err)\n\t\t\t}\n\n\t\t\tverify(t, dir, config, roots)\n\t\t})\n\t}\n}\n\nfunc modifyNode[N any](t *testing.T, directory string, encoder stock.ValueEncoder[N], modify func(n *N)) {\n\tt.Helper()\n\tstock, err := file.OpenStock[uint64](encoder, directory)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to open stock\")\n\t}\n\n\tids, err := stock.GetIds()\n\tif err != nil {\n\t\tt.Fatalf(\"failed to get stock ids: %v\", err)\n\t}\n\n\tidx, found := getFirstElementInSet(ids)\n\tif !found {\n\t\tt.SkipNow()\n\t}\n\n\tnode, err := stock.Get(idx)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to load node from stock: %v\", err)\n\t}\n\n\tmodify(&node)\n\n\tif err := stock.Set(idx, node); err != nil {\n\t\tt.Fatalf(\"failed to update node: %v\", err)\n\t}\n\n\tif err := stock.Close(); err != nil {\n\t\tt.Fatalf(\"failed to close stock: %v\", err)\n\t}\n}\n\nfunc fillTestForest(dir string, config MptConfig) (roots []Root, err error) {\n\tconst N = 100\n\tforestConfig := ForestConfig{Mode: Immutable, CacheCapacity: 1024}\n\tforest, err := OpenFileForest(dir, config, forestConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\troot := NewNodeReference(EmptyId())\n\tfor i := 0; i < N; i++ {\n\t\taddr := common.Address{byte(i)}\n\t\troot, err = forest.SetAccountInfo(&root, addr, AccountInfo{Nonce: common.ToNonce(1), CodeHash: common.Keccak256([]byte{1})})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfor j := 0; j < N; j++ {\n\t\t\troot, err = forest.SetValue(&root, addr, common.Key{byte(j)}, common.Value{byte(i + j + 1)})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\terr = forest.Freeze(&root)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\thash, _, err := forest.updateHashesFor(&root)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\troots = append(roots, Root{\n\t\t\tNodeRef: root,\n\t\t\tHash:    hash,\n\t\t})\n\t}\n\n\treturn roots, forest.Close()\n}\n\nfunc isDirectory(path string) bool {\n\tinfo, err := os.Stat(path)\n\tif err != nil {\n\t\treturn false\n\t}\n\treturn info.IsDir()\n}\n\nfunc getFirstElementInSet(set stock.IndexSet[uint64]) (uint64, bool) {\n\tfor i := set.GetLowerBound(); i < set.GetUpperBound(); i++ {\n\t\tif set.Contains(i) {\n\t\t\treturn i, true\n\t\t}\n\t}\n\treturn 0, false\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/verification_test.go b/go/database/mpt/verification_test.go
--- a/go/database/mpt/verification_test.go	(revision 1feae588e951ed0766d029a10d97fb1fbc45fe7e)
+++ b/go/database/mpt/verification_test.go	(date 1717063402452)
@@ -608,6 +608,53 @@
 	}
 }
 
+func TestVerification_ForestVerificationObserverReportsError(t *testing.T) {
+	runVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {
+
+		ctrl := gomock.NewController(t)
+		observer := NewMockVerificationObserver(ctrl)
+
+		gomock.InOrder(
+			observer.EXPECT().StartVerification(),
+			observer.EXPECT().Progress(gomock.Any()).MinTimes(1),
+			observer.EXPECT().EndVerification(gomock.Not(nil)),
+		)
+
+		encoder, _, _, _ := getEncoder(config)
+
+		modifyNode(t, dir+"/accounts", encoder, func(node *AccountNode) {
+			node.info.Balance[2]++
+		})
+
+		if err := VerifyFileForest(dir, config, roots, observer); err == nil {
+			t.Errorf("found unexpected error in fresh forest: %v", err)
+		}
+	})
+}
+
+func TestVerification_VerificationObserverReportsError(t *testing.T) {
+	runVerificationTest(t, func(t *testing.T, dir string, config MptConfig, roots []Root) {
+		ctrl := gomock.NewController(t)
+		observer := NewMockVerificationObserver(ctrl)
+
+		gomock.InOrder(
+			observer.EXPECT().StartVerification(),
+			observer.EXPECT().Progress(gomock.Any()).MinTimes(1),
+			observer.EXPECT().EndVerification(gomock.Not(nil)),
+		)
+
+		encoder, _, _, _ := getEncoder(config)
+
+		modifyNode(t, dir+"/accounts", encoder, func(node *AccountNode) {
+			node.info.Balance[2]++
+		})
+
+		if err := VerifyCodesAndForest(dir, config, roots, observer); err == nil {
+			t.Errorf("found unexpected error in fresh forest: %v", err)
+		}
+	})
+}
+
 func runVerificationTest(t *testing.T, verify func(t *testing.T, dir string, config MptConfig, roots []Root)) {
 	t.Helper()
 	for _, config := range allMptConfigs {
Index: go/database/mpt/verification.go
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// Copyright (c) 2024 Fantom Foundation\n//\n// Use of this software is governed by the Business Source License included\n// in the LICENSE file and at fantom.foundation/bsl11.\n//\n// Change Date: 2028-4-16\n//\n// On the date above, in accordance with the Business Source License, use of\n// this software will be governed by the GNU Lesser General Public License v3.\n\npackage mpt\n\n//go:generate mockgen -source verification.go -destination verification_mocks.go -package mpt\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"path/filepath\"\n\t\"sort\"\n\n\t\"github.com/Fantom-foundation/Carmen/go/backend/stock\"\n\t\"github.com/Fantom-foundation/Carmen/go/backend/stock/file\"\n\t\"github.com/Fantom-foundation/Carmen/go/common\"\n\t\"github.com/Fantom-foundation/Carmen/go/database/mpt/shared\"\n\t\"github.com/pbnjay/memory\"\n)\n\n// VerificationObserver is a listener interface for tracking the progress of the verification\n// of a forest. It can, for instance, be implemented by a user interface to keep the user updated\n// on current activities.\ntype VerificationObserver interface {\n\tStartVerification()\n\tProgress(msg string)\n\tEndVerification(res error)\n}\n\n// NilVerificationObserver is a trivial implementation of the observer interface above which\n// ignores all reported events.\ntype NilVerificationObserver struct{}\n\nfunc (NilVerificationObserver) StartVerification()        {}\nfunc (NilVerificationObserver) Progress(msg string)       {}\nfunc (NilVerificationObserver) EndVerification(res error) {}\n\n// VerifyCodesAndForest runs validation checks on the forest and code hashes\n// stored in the given directory.\n// Forest checks:\n//   - all required files are present and can be read\n//   - all referenced nodes are present\n//   - all hashes are consistent\n//\n// Code Hashes checks:\n//  1. Fatal checks\n//     - all CodeHashes of accounts are present in the code file\n//     - all byte-codes within the code file matches their hashed representation in accounts\n//  2. Non-fatal checks\n//     - there are no extra Code Hashes not referenced by any account\nfunc VerifyCodesAndForest(directory string, config MptConfig, roots []Root, observer VerificationObserver) (res error) {\n\tif observer == nil {\n\t\tobserver = NilVerificationObserver{}\n\t}\n\n\tobserver.StartVerification()\n\tdefer observer.EndVerification(res)\n\n\t// Open stock data structures for content verification.\n\tobserver.Progress(\"Obtaining read access to files ...\")\n\tsource, err := openVerificationNodeSource(directory, config)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer source.Close()\n\n\terr = verifyContractCodes(directory, source, observer)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = verifyForest(directory, config, roots, source, observer)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// VerifyFileForest runs list of validation checks on the forest stored in the given\n// directory. These checks include:\n//   - all required files are present and can be read\n//   - all referenced nodes are present\n//   - all hashes are consistent\nfunc VerifyFileForest(directory string, config MptConfig, roots []Root, observer VerificationObserver) (res error) {\n\tif observer == nil {\n\t\tobserver = NilVerificationObserver{}\n\t}\n\n\tobserver.StartVerification()\n\tdefer observer.EndVerification(res)\n\n\t// Open stock data structures for content verification.\n\tobserver.Progress(\"Obtaining read access to files ...\")\n\tsource, err := openVerificationNodeSource(directory, config)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer source.Close()\n\treturn verifyForest(directory, config, roots, source, observer)\n}\n\nfunc verifyForest(directory string, config MptConfig, roots []Root, source *verificationNodeSource, observer VerificationObserver) (res error) {\n\t// ------------------------- Meta-Data Checks -----------------------------\n\n\tobserver.Progress(fmt.Sprintf(\"Checking forest stored in %s ...\", directory))\n\n\t// Verify stock data structures.\n\tobserver.Progress(\"Checking meta-data ...\")\n\taccountEncoder, branchEncoder, extensionEncoder, valueEncoder := getEncoder(config)\n\tif err := file.VerifyStock[uint64](directory+\"/accounts\", accountEncoder); err != nil {\n\t\treturn err\n\t}\n\tif err := file.VerifyStock[uint64](directory+\"/branches\", branchEncoder); err != nil {\n\t\treturn err\n\t}\n\tif err := file.VerifyStock[uint64](directory+\"/extensions\", extensionEncoder); err != nil {\n\t\treturn err\n\t}\n\tif err := file.VerifyStock[uint64](directory+\"/values\", valueEncoder); err != nil {\n\t\treturn err\n\t}\n\n\t// ----------------- First Pass: check Node References --------------------\n\n\t// Check that all IDs used to reference other nodes are valid.\n\tobserver.Progress(\"Checking node references ...\")\n\tcheckId := func(ref NodeReference) error {\n\t\tif source.isValid(ref.Id()) {\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"contains invalid reference to node %v\", ref.Id())\n\t}\n\n\t// Check that roots are valid.\n\terrs := []error{}\n\tfor _, root := range roots {\n\t\tif err := checkId(root.NodeRef); err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\tif len(errs) > 0 {\n\t\treturn errors.Join(errs...)\n\t}\n\n\terr := source.forAllInnerNodes(func(node Node) error {\n\t\tswitch n := node.(type) {\n\t\tcase *AccountNode:\n\t\t\treturn checkId(n.storage)\n\t\tcase *ExtensionNode:\n\t\t\treturn checkId(n.next)\n\t\tcase *BranchNode:\n\t\t\terrs := []error{}\n\t\t\tfor i := 0; i < len(n.children); i++ {\n\t\t\t\tif err := checkId(n.children[i]); err != nil {\n\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn errors.Join(errs...)\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// -------------------- Further Passes: node hashes -----------------------\n\n\thasher := config.Hashing.createHasher()\n\thash := func(node Node) (common.Hash, error) {\n\t\toverrideId := ValueId((^uint64(0)) >> 2)\n\t\tif _, ok := node.(EmptyNode); ok {\n\t\t\toverrideId = EmptyId()\n\t\t}\n\t\tsource.setNodeOverride(overrideId, node)\n\t\tdefer source.clearOverride()\n\t\tref := NewNodeReference(overrideId)\n\t\treturn hasher.getHash(&ref, source)\n\t}\n\temptyNodeHash, err := hash(EmptyNode{})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to hash empty node: %v\", err)\n\t}\n\n\t// Check roots for Archive node\n\tif source.getConfig().HashStorageLocation == HashStoredWithNode {\n\t\t// Check hashes of roots.\n\t\tobserver.Progress(fmt.Sprintf(\"Checking %d root hashes ...\", len(roots)))\n\t\trefIds := newNodeIds(uint64(len(roots)))\n\t\tfor _, root := range roots {\n\t\t\trefIds.Put(root.NodeRef.id)\n\t\t}\n\t\tisEmbedded := func(node Node) (bool, error) { return false, nil } // root node cannot be embedded\n\t\thashes, _, err := loadNodeHashes(refIds, source, isEmbedded, emptyNodeHash)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, root := range roots {\n\t\t\twant := hashes[root.NodeRef.Id()]\n\t\t\tgot := root.Hash\n\t\t\tif want != got {\n\t\t\t\treturn fmt.Errorf(\"inconsistent hash for root node %v, want %v, got %v\", root.NodeRef.Id(), want, got)\n\t\t\t}\n\t\t}\n\t}\n\n\terr = verifyHashes(\n\t\t\"account\", source, source.accounts, source.accountIds, emptyNodeHash, roots, observer,\n\t\tfunc(node *AccountNode) (common.Hash, error) { return hash(node) },\n\t\tfunc(node *AccountNode) (common.Hash, bool) { return node.GetHash() },\n\t\tfunc(node Node) (bool, error) { return hasher.isEmbedded(node, source) },\n\t\tfunc(id NodeId) bool { return id.IsAccount() },\n\t\tfunc(node *AccountNode, hashes map[NodeId]common.Hash, embedded map[NodeId]bool) {\n\t\t\tnode.storageHash = hashes[node.storage.Id()]\n\t\t\tnode.storageHashDirty = false\n\t\t},\n\t\tfunc(node *AccountNode, ids *nodeIdCollection) {\n\t\t\tids.Put(node.storage.Id())\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = verifyHashes(\n\t\t\"branch\", source, source.branches, source.branchIds, emptyNodeHash, roots, observer,\n\t\tfunc(node *BranchNode) (common.Hash, error) { return hash(node) },\n\t\tfunc(node *BranchNode) (common.Hash, bool) { return node.GetHash() },\n\t\tfunc(node Node) (bool, error) { return hasher.isEmbedded(node, source) },\n\t\tfunc(id NodeId) bool { return id.IsBranch() },\n\t\tfunc(node *BranchNode, hashes map[NodeId]common.Hash, embedded map[NodeId]bool) {\n\t\t\tfor i := 0; i < 16; i++ {\n\t\t\t\tchild := node.children[i]\n\t\t\t\tif !child.Id().IsEmpty() && embedded[child.Id()] {\n\t\t\t\t\tnode.setEmbedded(byte(i), true)\n\t\t\t\t}\n\t\t\t\tif child := node.children[i]; !node.isEmbedded(byte(i)) && !child.Id().IsEmpty() {\n\t\t\t\t\thash, found := hashes[child.Id()]\n\t\t\t\t\tif !found {\n\t\t\t\t\t\tpanic(fmt.Sprintf(\"missing hash for %v\\n\", child.Id()))\n\t\t\t\t\t}\n\t\t\t\t\tnode.hashes[i] = hash\n\t\t\t\t}\n\t\t\t}\n\t\t\tnode.dirtyHashes = 0\n\t\t},\n\t\tfunc(node *BranchNode, ids *nodeIdCollection) {\n\t\t\tfor i := 0; i < 16; i++ {\n\t\t\t\t// ID may be an embedded child, it will be determined later while hashing\n\t\t\t\tids.Put(node.children[i].Id())\n\t\t\t}\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = verifyHashes(\n\t\t\"extension\", source, source.extensions, source.extensionIds, emptyNodeHash, roots, observer,\n\t\tfunc(node *ExtensionNode) (common.Hash, error) { return hash(node) },\n\t\tfunc(node *ExtensionNode) (common.Hash, bool) { return node.GetHash() },\n\t\tfunc(node Node) (bool, error) { return hasher.isEmbedded(node, source) },\n\t\tfunc(id NodeId) bool { return id.IsExtension() },\n\t\tfunc(node *ExtensionNode, hashes map[NodeId]common.Hash, embedded map[NodeId]bool) {\n\t\t\tnode.nextHash = hashes[node.next.Id()]\n\t\t\tnode.nextHashDirty = false\n\t\t\tnode.nextIsEmbedded = embedded[node.next.Id()]\n\t\t},\n\t\tfunc(node *ExtensionNode, ids *nodeIdCollection) {\n\t\t\tids.Put(node.next.Id())\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = verifyHashes(\n\t\t\"value\", source, source.values, source.valueIds, emptyNodeHash, roots, observer,\n\t\tfunc(node *ValueNode) (common.Hash, error) { return hash(node) },\n\t\tfunc(node *ValueNode) (common.Hash, bool) { return node.GetHash() },\n\t\tfunc(node Node) (bool, error) { return hasher.isEmbedded(node, source) },\n\t\tfunc(id NodeId) bool { return id.IsValue() },\n\t\tfunc(*ValueNode, map[NodeId]common.Hash, map[NodeId]bool) {},\n\t\tfunc(node *ValueNode, ids *nodeIdCollection) {},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc verifyHashes[N any](\n\tname string,\n\tsource *verificationNodeSource,\n\tstock stock.Stock[uint64, N],\n\tids stock.IndexSet[uint64],\n\thashOfEmptyNode common.Hash,\n\troots []Root,\n\tobserver VerificationObserver,\n\thash func(*N) (common.Hash, error),\n\treadHash func(*N) (common.Hash, bool),\n\tisEmbedded func(Node) (bool, error),\n\tisNodeType func(NodeId) bool,\n\tfillInChildrenHashes func(*N, map[NodeId]common.Hash, map[NodeId]bool),\n\tcollectChildrenIds func(*N, *nodeIdCollection),\n) error {\n\tmode := source.getConfig().HashStorageLocation\n\tswitch mode {\n\tcase HashStoredWithNode:\n\t\treturn verifyHashesStoredWithNodes(name, source, stock, ids, hashOfEmptyNode, observer, hash, readHash, isEmbedded, fillInChildrenHashes, collectChildrenIds)\n\tcase HashStoredWithParent:\n\t\treturn verifyHashesStoredWithParents(name, source, stock, ids, roots, observer, hash, isNodeType)\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown hash storage location: %v\", mode)\n\t}\n}\n\n// nodeIdCollection is a struct that collects NodeIds.\n// It allows for adding the IDs in the map so that duplicities are eliminated.\n// It maintains an additional slice, which is used for exporting collected NodeIDs\n// ordered.\n// The slice is pre-allocated with the input capacity.\ntype nodeIdCollection struct {\n\tnodeIds     map[NodeId]struct{}\n\tnodeIdsKeys []NodeId\n}\n\n// newNodeIds creates a new NodeIDs collector.\n// The input capacity is used for allocating a slice,\n// which is used for exporting sorted and unique NodeIds.\nfunc newNodeIds(capacity uint64) *nodeIdCollection {\n\treturn &nodeIdCollection{\n\t\tnodeIds:     make(map[NodeId]struct{}),\n\t\tnodeIdsKeys: make([]NodeId, 0, capacity),\n\t}\n}\n\n// Put adds node ID into this structure if it is not present yet.\nfunc (n *nodeIdCollection) Put(id NodeId) {\n\tn.nodeIds[id] = struct{}{}\n}\n\nfunc (n *nodeIdCollection) Size() uint64 {\n\treturn uint64(len(n.nodeIds))\n}\n\n// DrainToOrderedKeys returns accumulated keys ordered.\n// The accumulated keys are drained.\n// It means that repeated call to this method will not return the same keys again.\n// The returned slice is re-used for further calls of this method to save on memory allocations.\nfunc (n *nodeIdCollection) DrainToOrderedKeys() []NodeId {\n\tn.nodeIdsKeys = n.nodeIdsKeys[0:0]\n\t// collect keys ...\n\tfor id := range n.nodeIds {\n\t\tn.nodeIdsKeys = append(n.nodeIdsKeys, id)\n\t}\n\tn.nodeIds = make(map[NodeId]struct{}) // remove items to save space\n\n\t// ... and sort\n\tsort.Slice(n.nodeIdsKeys, func(i, j int) bool {\n\t\treturn n.nodeIdsKeys[i] < n.nodeIdsKeys[j]\n\t})\n\n\treturn n.nodeIdsKeys\n}\n\n// loadNodeHashes loads hashes of nodes from the input map nodeIdCollection.\n// This method optimizes I/O access and memory.\n// For this reason, it collects all nodeIdCollection from the input map and copies then to a slice, which is sorted.\n// The nodes to be hashed are loaded in sequence then using the sorted slice.\n// To save memory, this method clears the input map while coping the keys into the slice.\n// It means that the map content cannot be used after this method executes.\n// Furthermore, the slice for storing map keys is passes as the input.\n// It must be an empty slice, but it can be re-used for multiple calls of this method.\n// This method returns hashed nodes for the input ID and a map with embedded node IDs.\nfunc loadNodeHashes(\n\tnodeIds *nodeIdCollection,\n\tsource *verificationNodeSource,\n\tisEmbedded func(Node) (bool, error),\n\thashOfEmptyNode common.Hash,\n) (map[NodeId]common.Hash, map[NodeId]bool, error) {\n\tnodeIdsKeys := nodeIds.DrainToOrderedKeys()\n\t// Load hashes from disk\n\thashes := make(map[NodeId]common.Hash, len(nodeIdsKeys)+1)\n\thashes[EmptyId()] = hashOfEmptyNode\n\tembedded := map[NodeId]bool{}\n\tfor _, id := range nodeIdsKeys {\n\t\tvar node Node\n\t\tif id.IsBranch() {\n\t\t\tn, err := source.branches.Get(id.Index())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tnode = &n\n\t\t} else if id.IsValue() {\n\t\t\tn, err := source.values.Get(id.Index())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tnode = &n\n\t\t} else if id.IsAccount() {\n\t\t\tn, err := source.accounts.Get(id.Index())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tnode = &n\n\t\t} else if id.IsExtension() {\n\t\t\tn, err := source.extensions.Get(id.Index())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tnode = &n\n\t\t}\n\n\t\tif !id.IsEmpty() {\n\t\t\thash, dirty := node.GetHash()\n\t\t\tif dirty {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"encountered dirty hash on disk for node %v\", id)\n\t\t\t}\n\t\t\thashes[id] = hash\n\t\t\tif res, err := isEmbedded(node); err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t} else if res {\n\t\t\t\tembedded[id] = true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn hashes, embedded, nil\n}\n\n// getBatchSize gets the size of batch used for a list of items stored in memory.\n// It is computed as 80% of the main memory divided by the input item size.\nfunc getBatchSize(itemSize uint) uint64 {\n\treturn uint64(float64(memory.TotalMemory()) * 0.8 / float64(itemSize))\n}\n\nfunc verifyHashesStoredWithNodes[N any](\n\tname string,\n\tsource *verificationNodeSource,\n\tstock stock.Stock[uint64, N],\n\tids stock.IndexSet[uint64],\n\thashOfEmptyNode common.Hash,\n\tobserver VerificationObserver,\n\thash func(*N) (common.Hash, error),\n\treadHash func(*N) (common.Hash, bool),\n\tisEmbedded func(Node) (bool, error),\n\tfillInChildrenHashes func(*N, map[NodeId]common.Hash, map[NodeId]bool),\n\tcollectChildrenIds func(*N, *nodeIdCollection),\n) error {\n\tbatchSize := getBatchSize(150) // empirically determined item size\n\n\t// re-used for each loop to save on allocations\n\treferencedIds := newNodeIds(batchSize / 3) // pre-allocate only a fraction of the capacity to prevent huge allocations and GC when not the whole batch is used.\n\n\t// check other nodes\n\tlowerBound := ids.GetLowerBound()\n\tupperBound := ids.GetLowerBound()\n\tvar batchNum int\n\n\tfor upperBound < ids.GetUpperBound() {\n\t\tbatchNum++\n\t\t// First step -- loop to collect Ids of node children\n\t\t// The number of child references determines the size of this batch\n\t\t// because some nodes like Branch can have many children while other nodes like Extension has just one or Value has none.\n\t\tobserver.Progress(fmt.Sprintf(\"Getting refeences to children for %ss (batch %d, size: %d)...\", name, batchNum, batchSize))\n\t\tfor referencedIds.Size() < batchSize && upperBound < ids.GetUpperBound() {\n\t\t\tif !ids.Contains(upperBound) {\n\t\t\t\tupperBound++\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnode, err := stock.Get(upperBound)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcollectChildrenIds(&node, referencedIds)\n\t\t\tupperBound++\n\t\t}\n\n\t\t// Second step - sort IDs and load hashes from the disk\n\t\tobserver.Progress(fmt.Sprintf(\"Loading %d child hashes for %ss (batch %d, size: %d)...\", referencedIds.Size(), name, batchNum, batchSize))\n\t\thashes, embedded, err := loadNodeHashes(referencedIds, source, isEmbedded, hashOfEmptyNode)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Third step - read again the nodes, fill-in collected child hashes, compare hashes\n\t\tobserver.Progress(fmt.Sprintf(\"Checking hashes of up to %d %ss (batch %d, size: %d)...\", upperBound-lowerBound, name, batchNum, batchSize))\n\t\tfor i := lowerBound; i < upperBound; i++ {\n\t\t\tif !ids.Contains(i) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnode, err := stock.Get(i)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfillInChildrenHashes(&node, hashes, embedded)\n\t\t\twant, err := hash(&node)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tgot, dirty := readHash(&node)\n\t\t\tif dirty {\n\t\t\t\treturn fmt.Errorf(\"encountered dirty hash for node: %v\", i)\n\t\t\t}\n\n\t\t\tif got != want {\n\t\t\t\treturn fmt.Errorf(\"invalid hash stored for node %v, want %v, got %v\", i, want, got)\n\t\t\t}\n\t\t}\n\n\t\tlowerBound = upperBound // move to next window\n\t}\n\n\treturn nil\n}\n\nfunc verifyHashesStoredWithParents[N any](\n\tname string,\n\tsource *verificationNodeSource,\n\tstock stock.Stock[uint64, N],\n\tids stock.IndexSet[uint64],\n\troots []Root,\n\tobserver VerificationObserver,\n\thash func(*N) (common.Hash, error),\n\tisNodeType func(NodeId) bool,\n) error {\n\tbatchSize := getBatchSize(32) // a batch stores 32byte hashes\n\t// Load nodes of current type from disk\n\tfor batch := ids.GetLowerBound(); batch < ids.GetUpperBound(); batch += batchSize {\n\t\tlowerBound := batch\n\t\tupperBound := batch + batchSize\n\t\tif upperBound > ids.GetUpperBound() {\n\t\t\tupperBound = ids.GetUpperBound()\n\t\t}\n\n\t\tobserver.Progress(fmt.Sprintf(\"Hashing up to %d %ss (batch %d of %d)...\", upperBound-lowerBound, name, batch/batchSize+1, ids.GetUpperBound()/batchSize+1))\n\t\thashes := make([]common.Hash, upperBound-lowerBound)\n\t\tfor i := lowerBound; i < upperBound; i++ {\n\t\t\tif ids.Contains(i) {\n\t\t\t\tnode, err := stock.Get(i)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\th, err := hash(&node)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\thashes[i-lowerBound] = h\n\t\t\t}\n\t\t}\n\n\t\t// Check hashes of roots.\n\t\tcheckNodeHash := func(id NodeId, hash common.Hash) error {\n\t\t\tif !isNodeType(id) || id.Index() < lowerBound || id.Index() >= upperBound {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\twant := hashes[id.Index()-lowerBound]\n\t\t\tif hash == want {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"inconsistent hash for node %v, want %v, got %v\", id, want, hash)\n\t\t}\n\n\t\tfor _, root := range roots {\n\t\t\tif err := checkNodeHash(root.NodeRef.Id(), root.Hash); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Check that all nodes referencing other nodes use the right hashes.\n\t\tcheckContainedHashes := func(node Node) error {\n\t\t\tswitch n := node.(type) {\n\t\t\tcase *AccountNode:\n\t\t\t\treturn checkNodeHash(n.storage.Id(), n.storageHash)\n\t\t\tcase *ExtensionNode:\n\t\t\t\tif !n.nextIsEmbedded {\n\t\t\t\t\treturn checkNodeHash(n.next.Id(), n.nextHash)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\tcase *BranchNode:\n\t\t\t\t{\n\t\t\t\t\terrs := []error{}\n\t\t\t\t\tfor i := 0; i < len(n.children); i++ {\n\t\t\t\t\t\tif !n.isEmbedded(byte(i)) {\n\t\t\t\t\t\t\tif err := checkNodeHash(n.children[i].Id(), n.hashes[i]); err != nil {\n\t\t\t\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn errors.Join(errs...)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\tobserver.Progress(fmt.Sprintf(\"Checking hash references of up to %d %ss ...\", upperBound-lowerBound, name))\n\t\tif err := source.forAllInnerNodes(checkContainedHashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// verifyContractCodes runs list of validation checks on accounts and on the\n// code file stored in the given directory. These checks include:\n// 1) Fatal checks\n// - All CodeHashes within accounts are present in the code file\n// - All CodeHashes within the code file are correct matching the contract byte-codes\n// 2) Non-fatal checks\n// - There are no extra Code Hashes not referenced by any account\nfunc verifyContractCodes(directory string, source *verificationNodeSource, observer VerificationObserver) error {\n\tobserver.Progress(fmt.Sprintf(\"Checking contract codes ...\"))\n\n\tcodeFile := filepath.Join(directory, \"codes.dat\")\n\tcodes, err := readCodes(codeFile)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcheckedHashes := make(map[common.Hash]bool)\n\tcheck := func(acc *AccountNode) error {\n\t\tcodeHash := acc.info.CodeHash\n\t\t// skip accounts that are not contracts\n\t\tif codeHash == emptyCodeHash {\n\t\t\treturn nil\n\t\t}\n\t\t// no need to check the hash correctness more than once\n\t\tif _, exists := checkedHashes[codeHash]; exists {\n\t\t\treturn nil\n\t\t}\n\t\t// mark an already checked hash\n\t\tcheckedHashes[codeHash] = true\n\t\t// check that the code hash is present in the code file\n\t\tbyteCode, exists := codes[codeHash]\n\t\tif !exists {\n\t\t\treturn fmt.Errorf(\"hash %x is missing in code file\", codeHash)\n\t\t}\n\t\t// check correctness of the code hash\n\t\tif got, want := common.Keccak256(byteCode), codeHash; got.Compare(&want) != 0 {\n\t\t\treturn fmt.Errorf(\"unexpected code hash, got: %x want: %x\", got, want)\n\t\t}\n\t\treturn nil\n\t}\n\terr = source.forAccountNodes(check)\n\n\t// find any extra hashes\n\tfor h, bc := range codes {\n\t\tif _, exists := checkedHashes[h]; !exists {\n\t\t\tobserver.Progress(fmt.Sprintf(\"Contract %x is not referenced by any account\\n\", h))\n\t\t\tif got, want := common.Keccak256(bc), &h; got.Compare(want) != 0 {\n\t\t\t\terr = errors.Join(err, fmt.Errorf(\"unexpected code hash, got: %x want: %x\", got, want))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn err\n}\n\ntype verificationNodeSource struct {\n\tconfig MptConfig\n\n\t// The lock guaranteeing exclusive access to the data directory.\n\tlock      common.LockFile\n\tdirectory string\n\n\t// The stock containers managing individual node types.\n\tbranches   stock.Stock[uint64, BranchNode]\n\textensions stock.Stock[uint64, ExtensionNode]\n\taccounts   stock.Stock[uint64, AccountNode]\n\tvalues     stock.Stock[uint64, ValueNode]\n\n\t// The sets of valid IDs of each type.\n\taccountIds   stock.IndexSet[uint64]\n\tbranchIds    stock.IndexSet[uint64]\n\textensionIds stock.IndexSet[uint64]\n\tvalueIds     stock.IndexSet[uint64]\n\n\t// A custom pair of node ID and Node to be overwritten for node resolution.\n\toverwriteId   NodeId\n\toverwriteNode Node\n}\n\nfunc openVerificationNodeSource(directory string, config MptConfig) (*verificationNodeSource, error) {\n\tlock, err := openStateDirectory(directory)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsuccess := false\n\taccountEncoder, branchEncoder, extensionEncoder, valueEncoder := getEncoder(config)\n\tbranches, err := file.OpenStock[uint64, BranchNode](branchEncoder, directory+\"/branches\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif !success {\n\t\t\tbranches.Close()\n\t\t}\n\t}()\n\textensions, err := file.OpenStock[uint64, ExtensionNode](extensionEncoder, directory+\"/extensions\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif !success {\n\t\t\textensions.Close()\n\t\t}\n\t}()\n\taccounts, err := file.OpenStock[uint64, AccountNode](accountEncoder, directory+\"/accounts\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif !success {\n\t\t\taccounts.Close()\n\t\t}\n\t}()\n\tvalues, err := file.OpenStock[uint64, ValueNode](valueEncoder, directory+\"/values\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif !success {\n\t\t\tvalues.Close()\n\t\t}\n\t}()\n\taccountIds, err := accounts.GetIds()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbranchIds, err := branches.GetIds()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\textensionIds, err := extensions.GetIds()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvalueIds, err := values.GetIds()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsuccess = true\n\treturn &verificationNodeSource{\n\t\tconfig:       config,\n\t\tlock:         lock,\n\t\tdirectory:    directory,\n\t\taccounts:     accounts,\n\t\tbranches:     branches,\n\t\textensions:   extensions,\n\t\tvalues:       values,\n\t\taccountIds:   accountIds,\n\t\tbranchIds:    branchIds,\n\t\textensionIds: extensionIds,\n\t\tvalueIds:     valueIds,\n\t}, nil\n}\n\nfunc (s *verificationNodeSource) getConfig() MptConfig {\n\treturn s.config\n}\n\nfunc (s *verificationNodeSource) getShared(id NodeId) (*shared.Shared[Node], error) {\n\tvar node Node\n\tvar err error\n\tif s.overwriteId == id && s.overwriteNode != nil {\n\t\tnode = s.overwriteNode\n\t} else if id.IsEmpty() {\n\t\tnode, err = EmptyNode{}, nil\n\t} else if id.IsAccount() {\n\t\taccount, e := s.accounts.Get(id.Index())\n\t\tnode, err = &account, e\n\t} else if id.IsBranch() {\n\t\tbranch, e := s.branches.Get(id.Index())\n\t\tnode, err = &branch, e\n\t} else if id.IsExtension() {\n\t\text, e := s.extensions.Get(id.Index())\n\t\tnode, err = &ext, e\n\t} else if id.IsValue() {\n\t\tvalue, e := s.values.Get(id.Index())\n\t\tnode, err = &value, e\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn shared.MakeShared[Node](node), nil\n}\n\nfunc (s *verificationNodeSource) getReadAccess(ref *NodeReference) (shared.ReadHandle[Node], error) {\n\tnode, err := s.getShared(ref.Id())\n\tif err != nil {\n\t\treturn shared.ReadHandle[Node]{}, err\n\t}\n\treturn node.GetReadHandle(), nil\n}\n\nfunc (s *verificationNodeSource) getViewAccess(ref *NodeReference) (shared.ViewHandle[Node], error) {\n\tnode, err := s.getShared(ref.Id())\n\tif err != nil {\n\t\treturn shared.ViewHandle[Node]{}, err\n\t}\n\treturn node.GetViewHandle(), nil\n}\n\nfunc (s *verificationNodeSource) getHashFor(*NodeReference) (common.Hash, error) {\n\tpanic(\"hash resolution not supported\")\n}\n\nfunc (s *verificationNodeSource) hashKey(key common.Key) common.Hash {\n\treturn common.Keccak256(key[:])\n}\n\nfunc (s *verificationNodeSource) hashAddress(address common.Address) common.Hash {\n\treturn common.Keccak256(address[:])\n}\n\nfunc (s *verificationNodeSource) Close() error {\n\terr := errors.Join(\n\t\ts.accounts.Close(),\n\t\ts.branches.Close(),\n\t\ts.extensions.Close(),\n\t\ts.values.Close(),\n\t)\n\tif err == nil {\n\t\terr = markClean(s.directory)\n\t}\n\treturn errors.Join(\n\t\terr,\n\t\ts.lock.Release(),\n\t)\n}\n\nfunc (s *verificationNodeSource) isValid(id NodeId) bool {\n\tif id.IsEmpty() {\n\t\treturn true\n\t}\n\tif id.IsAccount() {\n\t\treturn s.accountIds.Contains(id.Index())\n\t}\n\tif id.IsBranch() {\n\t\treturn s.branchIds.Contains(id.Index())\n\t}\n\tif id.IsExtension() {\n\t\treturn s.extensionIds.Contains(id.Index())\n\t}\n\tif id.IsValue() {\n\t\treturn s.valueIds.Contains(id.Index())\n\t}\n\treturn false\n}\n\nfunc (s *verificationNodeSource) setNodeOverride(id NodeId, node Node) {\n\ts.overwriteId = id\n\ts.overwriteNode = node\n}\n\nfunc (s *verificationNodeSource) clearOverride() {\n\ts.overwriteNode = nil\n}\n\nfunc (s *verificationNodeSource) forAllInnerNodes(check func(Node) error) error {\n\treturn s.forNodes(func(_ NodeId, node Node) error { return check(node) }, true, true, true, false)\n}\n\nfunc (s *verificationNodeSource) forAllNodes(check func(NodeId, Node) error) error {\n\treturn s.forNodes(check, true, true, true, true)\n}\n\nfunc (s *verificationNodeSource) forAccountNodes(check func(*AccountNode) error) error {\n\tvar errs []error\n\n\tfor i := s.accountIds.GetLowerBound(); i < s.accountIds.GetUpperBound(); i++ {\n\t\tif s.accountIds.Contains(i) {\n\t\t\taccount, err := s.accounts.Get(i)\n\t\t\tif err != nil { // with IO errors => stop immediately\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := check(&account); err != nil {\n\t\t\t\terrs = append(errs, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errors.Join(errs...)\n}\n\nfunc (s *verificationNodeSource) forNodes(\n\tcheck func(NodeId, Node) error,\n\tbranches, extensions, accounts, values bool,\n) error {\n\terrs := []error{}\n\tif branches {\n\t\tfor i := s.branchIds.GetLowerBound(); i < s.branchIds.GetUpperBound(); i++ {\n\t\t\tif s.branchIds.Contains(i) {\n\t\t\t\tbranch, err := s.branches.Get(i)\n\t\t\t\tif err != nil { // with IO errors => stop immediately\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := check(BranchId(i), &branch); err != nil {\n\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif extensions {\n\t\tfor i := s.extensionIds.GetLowerBound(); i < s.extensionIds.GetUpperBound(); i++ {\n\t\t\tif s.extensionIds.Contains(i) {\n\t\t\t\textension, err := s.extensions.Get(i)\n\t\t\t\tif err != nil { // with IO errors => stop immediately\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := check(ExtensionId(i), &extension); err != nil {\n\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif accounts {\n\t\tfor i := s.accountIds.GetLowerBound(); i < s.accountIds.GetUpperBound(); i++ {\n\t\t\tif s.accountIds.Contains(i) {\n\t\t\t\taccount, err := s.accounts.Get(i)\n\t\t\t\tif err != nil { // with IO errors => stop immediately\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := check(AccountId(i), &account); err != nil {\n\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif values {\n\t\tfor i := s.valueIds.GetLowerBound(); i < s.valueIds.GetUpperBound(); i++ {\n\t\t\tif s.valueIds.Contains(i) {\n\t\t\t\tvalue, err := s.values.Get(i)\n\t\t\t\tif err != nil { // with IO errors => stop immediately\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := check(ValueId(i), &value); err != nil {\n\t\t\t\t\terrs = append(errs, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn errors.Join(errs...)\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/go/database/mpt/verification.go b/go/database/mpt/verification.go
--- a/go/database/mpt/verification.go	(revision 1feae588e951ed0766d029a10d97fb1fbc45fe7e)
+++ b/go/database/mpt/verification.go	(date 1717063156276)
@@ -61,7 +61,9 @@
 	}
 
 	observer.StartVerification()
-	defer observer.EndVerification(res)
+	defer func() {
+		observer.EndVerification(res)
+	}()
 
 	// Open stock data structures for content verification.
 	observer.Progress("Obtaining read access to files ...")
@@ -95,7 +97,9 @@
 	}
 
 	observer.StartVerification()
-	defer observer.EndVerification(res)
+	defer func() {
+		observer.EndVerification(res)
+	}()
 
 	// Open stock data structures for content verification.
 	observer.Progress("Obtaining read access to files ...")
